> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [www.zhihu.com](https://www.zhihu.com/question/443280657/answer/1785592611) ![](https://pic1.zhimg.com/v2-f165a7378f1cef32933c4782e17b1388_xs.jpg?source=1940ef5c)艾小仙​

Java 基础
-------

### **说说进程和线程的区别？**

进程是程序的一次执行，是系统进行资源分配和调度的独立单位，他的作用是是程序能够并发执行提高资源利用率和吞吐率。

由于进程是资源分配和调度的基本单位，因为进程的创建、销毁、切换产生大量的时间和空间的开销，进程的数量不能太多，而线程是比进程更小的能独立运行的基本单位，他是进程的一个实体，可以减少程序并发执行时的时间和空间开销，使得操作系统具有更好的并发性。

线程基本不拥有系统资源，只有一些运行时必不可少的资源，比如程序计数器、寄存器和栈，进程则占有堆、栈。

### **知道 synchronized 原理吗？**

synchronized 是 java 提供的原子性内置锁，这种内置的并且使用者看不到的锁也被称为**监视器锁**，使用 synchronized 之后，会在编译之后在同步的代码块前后加上 monitorenter 和 monitorexit 字节码指令，他依赖操作系统底层互斥锁实现。他的作用主要就是实现原子性操作和解决共享变量的内存可见性问题。

执行 monitorenter 指令时会尝试获取对象锁，如果对象没有被锁定或者已经获得了锁，锁的计数器 + 1。此时其他竞争锁的线程则会进入等待队列中。

执行 monitorexit 指令时则会把计数器 - 1，当计数器值为 0 时，则锁释放，处于等待队列中的线程再继续竞争锁。

synchronized 是排它锁，当一个线程获得锁之后，其他线程必须等待该线程释放锁后才能获得锁，而且由于 Java 中的线程和操作系统原生线程是一一对应的，线程被阻塞或者唤醒时时会从用户态切换到内核态，这种转换非常消耗性能。

从内存语义来说，加锁的过程会清除工作内存中的共享变量，再从主内存读取，而释放锁的过程则是将工作内存中的共享变量写回主内存。

_实际上大部分时候我认为说到 monitorenter 就行了，但是为了更清楚的描述，还是再具体一点_。

如果再深入到源码来说，synchronized 实际上有两个队列 waitSet 和 entryList。

1.  当多个线程进入同步代码块时，首先进入 entryList
2.  有一个线程获取到 monitor 锁后，就赋值给当前线程，并且计数器 + 1
3.  如果线程调用 wait 方法，将释放锁，当前线程置为 null，计数器 - 1，同时进入 waitSet 等待被唤醒，调用 notify 或者 notifyAll 之后又会进入 entryList 竞争锁
4.  如果线程执行完毕，同样释放锁，计数器 - 1，当前线程置为 null

![](https://pic1.zhimg.com/v2-9cb535d55d21dfe67c629f768df50883_r.jpg?source=1940ef5c)

### **那锁的优化机制了解吗？**

从 JDK1.6 版本之后，synchronized 本身也在不断优化锁的机制，有些情况下他并不会是一个很重量级的锁了。优化机制包括自适应锁、自旋锁、锁消除、锁粗化、轻量级锁和偏向锁。

锁的状态从低到高依次为**无锁 -> 偏向锁 -> 轻量级锁 -> 重量级锁**，升级的过程就是从低到高，降级在一定条件也是有可能发生的。

**自旋锁**：由于大部分时候，锁被占用的时间很短，共享变量的锁定时间也很短，所有没有必要挂起线程，用户态和内核态的来回上下文切换严重影响性能。自旋的概念就是让线程执行一个忙循环，可以理解为就是啥也不干，防止从用户态转入内核态，自旋锁可以通过设置 - XX:+UseSpining 来开启，自旋的默认次数是 10 次，可以使用 - XX:PreBlockSpin 设置。

**自适应锁**：自适应锁就是自适应的自旋锁，自旋的时间不是固定时间，而是由前一次在同一个锁上的自旋时间和锁的持有者状态来决定。

**锁消除**：锁消除指的是 JVM 检测到一些同步的代码块，完全不存在数据竞争的场景，也就是不需要加锁，就会进行锁消除。

**锁粗化**：锁粗化指的是有很多操作都是对同一个对象进行加锁，就会把锁的同步范围扩展到整个操作序列之外。

**偏向锁**：当线程访问同步块获取锁时，会在对象头和栈帧中的锁记录里存储偏向锁的线程 ID，之后这个线程再次进入同步块时都不需要 CAS 来加锁和解锁了，偏向锁会永远偏向第一个获得锁的线程，如果后续没有其他线程获得过这个锁，持有锁的线程就永远不需要进行同步，反之，当有其他线程竞争偏向锁时，持有偏向锁的线程就会释放偏向锁。可以用过设置 - XX:+UseBiasedLocking 开启偏向锁。

**轻量级锁**：JVM 的对象的对象头中包含有一些锁的标志位，代码进入同步块的时候，JVM 将会使用 CAS 方式来尝试获取锁，如果更新成功则会把对象头中的状态位标记为轻量级锁，如果更新失败，当前线程就尝试自旋来获得锁。

整个锁升级的过程非常复杂，我尽力去除一些无用的环节，简单来描述整个升级的机制。

简单点说，偏向锁就是通过对象头的偏向线程 ID 来对比，甚至都不需要 CAS 了，而轻量级锁主要就是通过 CAS 修改对象头锁记录和自旋来实现，重量级锁则是除了拥有锁的线程其他全部阻塞。

![](https://pic1.zhimg.com/v2-a04036ccc8906893955e06a47e97d38b_r.jpg?source=1940ef5c)

### **那对象头具体都包含哪些内容？**

在我们常用的 Hotspot 虚拟机中，对象在内存中布局实际包含 3 个部分：

1.  对象头
2.  实例数据
3.  对齐填充

而对象头包含两部分内容，Mark Word 中的内容会随着锁标志位而发生变化，所以只说存储结构就好了。

1.  对象自身运行时所需的数据，也被称为 Mark Word，也就是用于轻量级锁和偏向锁的关键点。具体的内容包含对象的 hashcode、分代年龄、轻量级锁指针、重量级锁指针、GC 标记、偏向锁线程 ID、偏向锁时间戳。
2.  存储类型指针，也就是指向类的元数据的指针，通过这个指针才能确定对象是属于哪个类的实例。

_如果是数组的话，则还包含了数组的长度_

![](https://pic2.zhimg.com/v2-bb7e2989c375f870122a61fcf8b9cf79_r.jpg?source=1940ef5c)

### **对于加锁，那再说下 ReentrantLock 原理？他和 synchronized 有什么区别？**

相比于 synchronized，ReentrantLock 需要显式的获取锁和释放锁，相对现在基本都是用 JDK7 和 JDK8 的版本，ReentrantLock 的效率和 synchronized 区别基本可以持平了。他们的主要区别有以下几点：

1.  等待可中断，当持有锁的线程长时间不释放锁的时候，等待中的线程可以选择放弃等待，转而处理其他的任务。
2.  公平锁：synchronized 和 ReentrantLock 默认都是非公平锁，但是 ReentrantLock 可以通过构造函数传参改变。只不过使用公平锁的话会导致性能急剧下降。
3.  绑定多个条件：ReentrantLock 可以同时绑定多个 Condition 条件对象。

ReentrantLock 基于 AQS(**AbstractQueuedSynchronizer 抽象队列同步器**) 实现。别说了，我知道问题了，AQS 原理我来讲。

AQS 内部维护一个 state 状态位，尝试加锁的时候通过 CAS(CompareAndSwap) 修改值，如果成功设置为 1，并且把当前线程 ID 赋值，则代表加锁成功，一旦获取到锁，其他的线程将会被阻塞进入阻塞队列自旋，获得锁的线程释放锁的时候将会唤醒阻塞队列中的线程，释放锁的时候则会把 state 重新置为 0，同时当前线程 ID 置为空。

![](https://pica.zhimg.com/v2-b4ff47cd91144a6c0301511312bb72ff_r.jpg?source=1940ef5c)

### **CAS 的原理呢？**

CAS 叫做 CompareAndSwap，比较并交换，主要是通过处理器的指令来保证操作的原子性，它包含三个操作数：

1.  变量内存地址，V 表示
2.  旧的预期值，A 表示
3.  准备设置的新值，B 表示

当执行 CAS 指令时，只有当 V 等于 A 时，才会用 B 去更新 V 的值，否则就不会执行更新操作。

### **那么 CAS 有什么缺点吗？**

CAS 的缺点主要有 3 点：

**ABA 问题**：ABA 的问题指的是在 CAS 更新的过程中，当读取到的值是 A，然后准备赋值的时候仍然是 A，但是实际上有可能 A 的值被改成了 B，然后又被改回了 A，这个 CAS 更新的漏洞就叫做 ABA。只是 ABA 的问题大部分场景下都不影响并发的最终效果。

Java 中有 AtomicStampedReference 来解决这个问题，他加入了预期标志和更新后标志两个字段，更新时不光检查值，还要检查当前的标志是否等于预期标志，全部相等的话才会更新。

**循环时间长开销大**：自旋 CAS 的方式如果长时间不成功，会给 CPU 带来很大的开销。

**只能保证一个共享变量的原子操作**：只对一个共享变量操作可以保证原子性，但是多个则不行，多个可以通过 AtomicReference 来处理或者使用锁 synchronized 实现。

### **好，说说 HashMap 原理吧？**

HashMap 主要由数组和链表组成，他不是线程安全的。核心的点就是 put 插入数据的过程，get 查询数据以及扩容的方式。JDK1.7 和 1.8 的主要区别在于头插和尾插方式的修改，头插容易导致 HashMap 链表死循环，并且 1.8 之后加入红黑树对性能有提升。

**put 插入数据流程**

往 map 插入元素的时候首先通过对 key hash 然后与数组长度 - 1 进行与运算 ((n-1)&hash)，都是 2 的次幂所以等同于取模，但是位运算的效率更高。找到数组中的位置之后，如果数组中没有元素直接存入，反之则判断 key 是否相同，key 相同就覆盖，否则就会插入到链表的尾部，如果链表的长度超过 8，则会转换成红黑树，最后判断数组长度是否超过默认的长度 * 负载因子也就是 12，超过则进行扩容。

![](https://pica.zhimg.com/v2-f441cfcab32180cb06cc3a4bdbc16900_r.jpg?source=1940ef5c)

**get 查询数据**

查询数据相对来说就比较简单了，首先计算出 hash 值，然后去数组查询，是红黑树就去红黑树查，链表就遍历链表查询就可以了。

**resize 扩容过程**

扩容的过程就是对 key 重新计算 hash，然后把数据拷贝到新的数组。

### **那多线程环境怎么使用 Map 呢？ConcurrentHashmap 了解过吗？**

多线程环境可以使用 Collections.synchronizedMap 同步加锁的方式，还可以使用 HashTable，但是同步的方式显然性能不达标，而 ConurrentHashMap 更适合高并发场景使用。

ConcurrentHashmap 在 JDK1.7 和 1.8 的版本改动比较大，1.7 使用 Segment+HashEntry 分段锁的方式实现，1.8 则抛弃了 Segment，改为使用 CAS+synchronized+Node 实现，同样也加入了红黑树，避免链表过长导致性能的问题。

**1.7 分段锁**

从结构上说，1.7 版本的 ConcurrentHashMap 采用分段锁机制，里面包含一个 Segment 数组，Segment 继承于 ReentrantLock，Segment 则包含 HashEntry 的数组，HashEntry 本身就是一个链表的结构，具有保存 key、value 的能力能指向下一个节点的指针。

实际上就是相当于每个 Segment 都是一个 HashMap，默认的 Segment 长度是 16，也就是支持 16 个线程的并发写，Segment 之间相互不会受到影响。

![](https://pic1.zhimg.com/v2-be077914a69cff759444a713e3384b1e_r.jpg?source=1940ef5c)

**put 流程**

其实发现整个流程和 HashMap 非常类似，只不过是先定位到具体的 Segment，然后通过 ReentrantLock 去操作而已，后面的流程我就简化了，因为和 HashMap 基本上是一样的。

1.  计算 hash，定位到 segment，segment 如果是空就先初始化
2.  使用 ReentrantLock 加锁，如果获取锁失败则尝试自旋，自旋超过次数就阻塞获取，保证一定获取锁成功
3.  遍历 HashEntry，就是和 HashMap 一样，数组中 key 和 hash 一样就直接替换，不存在就再插入链表，链表同样

![](https://pica.zhimg.com/v2-731ade899fc27f0ef88bc84c52c07bdb_r.jpg?source=1940ef5c)

**get 流程**

get 也很简单，key 通过 hash 定位到 segment，再遍历链表定位到具体的元素上，需要注意的是 value 是 volatile 的，所以 get 是不需要加锁的。

**1.8CAS+synchronized**

1.8 抛弃分段锁，转为用 CAS+synchronized 来实现，同样 HashEntry 改为 Node，也加入了红黑树的实现。主要还是看 put 的流程。

![](https://picx.zhimg.com/v2-71e0edc0ddd7cdfdbcf21a80584168fb_r.jpg?source=1940ef5c)

**put 流程**

1.  首先计算 hash，遍历 node 数组，如果 node 是空的话，就通过 CAS + 自旋的方式初始化
2.  如果当前数组位置是空则直接通过 CAS 自旋写入数据
3.  如果 hash==MOVED，说明需要扩容，执行扩容
4.  如果都不满足，就使用 synchronized 写入数据，写入数据同样判断链表、红黑树，链表写入和 HashMap 的方式一样，key hash 一样就覆盖，反之就尾插法，链表长度超过 8 就转换成红黑树

![](https://pic1.zhimg.com/v2-19e6a0bde9ec6a4a22c4b1046e3d2d79_r.jpg?source=1940ef5c)

**get 查询**

get 很简单，通过 key 计算 hash，如果 key hash 相同就返回，如果是红黑树按照红黑树获取，都不是就遍历链表获取。

### **volatile 原理知道吗？**

相比 synchronized 的加锁方式来解决共享变量的内存可见性问题，volatile 就是更轻量的选择，他没有上下文切换的额外开销成本。使用 volatile 声明的变量，可以确保值被更新的时候对其他线程立刻可见。volatile 使用内存屏障来保证不会发生指令重排，解决了内存可见性的问题。

我们知道，线程都是从主内存中读取共享变量到工作内存来操作，完成之后再把结果写回主内存，但是这样就会带来可见性问题。举个例子，假设现在我们是两级缓存的双核 CPU 架构，包含 L1、L2 两级缓存。

1.  线程 A 首先获取变量 X 的值，由于最初两级缓存都是空，所以直接从主内存中读取 X，假设 X 初始值为 0，线程 A 读取之后把 X 值都修改为 1，同时写回主内存。这时候缓存和主内存的情况如下图。

![](https://pica.zhimg.com/v2-5d13d1d458bcaa84af429a3fc7c9aef6_r.jpg?source=1940ef5c)

1.  线程 B 也同样读取变量 X 的值，由于 L2 缓存已经有缓存 X=1，所以直接从 L2 缓存读取，之后线程 B 把 X 修改为 2，同时写回 L2 和主内存。这时候的 X 值入下图所示。  
    那么线程 A 如果再想获取变量 X 的值，因为 L1 缓存已经有 x=1 了，所以这时候变量内存不可见问题就产生了，B 修改为 2 的值对 A 来说没有感知。  
    

![](https://picx.zhimg.com/v2-38e8b03e3ef612411a9b384bd32de0c1_r.jpg?source=1940ef5c)

那么，如果 X 变量用 volatile 修饰的话，当线程 A 再次读取变量 X 的话，CPU 就会根据缓存一致性协议强制线程 A 重新从主内存加载最新的值到自己的工作内存，而不是直接用缓存中的值。

再来说内存屏障的问题，volatile 修饰之后会加入不同的内存屏障来保证可见性的问题能正确执行。这里写的屏障基于书中提供的内容，但是实际上由于 CPU 架构不同，重排序的策略不同，提供的内存屏障也不一样，比如 x86 平台上，只有 StoreLoad 一种内存屏障。

1.  StoreStore 屏障，保证上面的普通写不和 volatile 写发生重排序
2.  StoreLoad 屏障，保证 volatile 写与后面可能的 volatile 读写不发生重排序
3.  LoadLoad 屏障，禁止 volatile 读与后面的普通读重排序
4.  LoadStore 屏障，禁止 volatile 读和后面的普通写重排序

![](https://pic4.zhimg.com/v2-bcac12c0945049a72b37fa1279b80ae2_r.jpg?source=1940ef5c)

### **那么说说你对 JMM 内存模型的理解？为什么需要 JMM？**

本身随着 CPU 和内存的发展速度差异的问题，导致 CPU 的速度远快于内存，所以现在的 CPU 加入了高速缓存，高速缓存一般可以分为 L1、L2、L3 三级缓存。基于上面的例子我们知道了这导致了缓存一致性的问题，所以加入了缓存一致性协议，同时导致了内存可见性的问题，而编译器和 CPU 的重排序导致了原子性和有序性的问题，JMM 内存模型正是对多线程操作下的一系列规范约束，因为不可能让程序员的代码去兼容所有的 CPU，通过 JMM 我们才屏蔽了不同硬件和操作系统内存的访问差异，这样保证了 Java 程序在不同的平台下达到一致的内存访问效果，同时也是保证在高效并发的时候程序能够正确执行。

![](https://pica.zhimg.com/v2-3053e047b418aa1e2362d581c37ba224_r.jpg?source=1940ef5c)

**原子性**：Java 内存模型通过 read、load、assign、use、store、write 来保证原子性操作，此外还有 lock 和 unlock，直接对应着 synchronized 关键字的 monitorenter 和 monitorexit 字节码指令。

**可见性**：可见性的问题在上面的回答已经说过，Java 保证可见性可以认为通过 volatile、synchronized、final 来实现。

**有序性**：由于处理器和编译器的重排序导致的有序性问题，Java 通过 volatile、synchronized 来保证。

**happen-before 规则**

虽然指令重排提高了并发的性能，但是 Java 虚拟机会对指令重排做出一些规则限制，并不能让所有的指令都随意的改变执行位置，主要有以下几点：

1.  单线程每个操作，happen-before 于该线程中任意后续操作
2.  volatile 写 happen-before 于后续对这个变量的读
3.  synchronized 解锁 happen-before 后续对这个锁的加锁
4.  final 变量的写 happen-before 于 final 域对象的读，happen-before 后续对 final 变量的读
5.  传递性规则，A 先于 B，B 先于 C，那么 A 一定先于 C 发生

### **说了半天，到底工作内存和主内存是什么？**

主内存可以认为就是物理内存，Java 内存模型中实际就是虚拟机内存的一部分。而工作内存就是 CPU 缓存，他有可能是寄存器也有可能是 L1\L2\L3 缓存，都是有可能的。

### **说说 ThreadLocal 原理？**

ThreadLocal 可以理解为线程本地变量，他会在每个线程都创建一个副本，那么在线程之间访问内部副本变量就行了，做到了线程之间互相隔离，相比于 synchronized 的做法是用空间来换时间。

ThreadLocal 有一个静态内部类 ThreadLocalMap，ThreadLocalMap 又包含了一个 Entry 数组，Entry 本身是一个弱引用，他的 key 是指向 ThreadLocal 的弱引用，Entry 具备了保存 key value 键值对的能力。

弱引用的目的是为了防止内存泄露，如果是强引用那么 ThreadLocal 对象除非线程结束否则始终无法被回收，弱引用则会在下一次 GC 的时候被回收。

但是这样还是会存在内存泄露的问题，假如 key 和 ThreadLocal 对象被回收之后，entry 中就存在 key 为 null，但是 value 有值的 entry 对象，但是永远没办法被访问到，同样除非线程结束运行。

但是只要 ThreadLocal 使用恰当，在使用完之后调用 remove 方法删除 Entry 对象，实际上是不会出现这个问题的。

![](https://pic3.zhimg.com/v2-e4e764bb5e8f3bf666ac73d3847ad80c_r.jpg?source=1940ef5c)

### **那引用类型有哪些？有什么区别？**

引用类型主要分为强软弱虚四种：

1.  强引用指的就是代码中普遍存在的赋值方式，比如 A a = new A() 这种。强引用关联的对象，永远不会被 GC 回收。
2.  软引用可以用 SoftReference 来描述，指的是那些有用但是不是必须要的对象。系统在发生内存溢出前会对这类引用的对象进行回收。
3.  弱引用可以用 WeakReference 来描述，他的强度比软引用更低一点，弱引用的对象下一次 GC 的时候一定会被回收，而不管内存是否足够。
4.  虚引用也被称作幻影引用，是最弱的引用关系，可以用 PhantomReference 来描述，他必须和 ReferenceQueue 一起使用，同样的当发生 GC 的时候，虚引用也会被回收。可以用虚引用来管理堆外内存。

### **线程池原理知道吗？**

首先线程池有几个核心的参数概念：

1.  最大线程数 maximumPoolSize
2.  核心线程数 corePoolSize
3.  活跃时间 keepAliveTime
4.  阻塞队列 workQueue
5.  拒绝策略 RejectedExecutionHandler

当提交一个新任务到线程池时，具体的执行流程如下：

1.  当我们提交任务，线程池会根据 corePoolSize 大小创建若干任务数量线程执行任务
2.  当任务的数量超过 corePoolSize 数量，后续的任务将会进入阻塞队列阻塞排队
3.  当阻塞队列也满了之后，那么将会继续创建 (maximumPoolSize-corePoolSize) 个数量的线程来执行任务，如果任务处理完成，maximumPoolSize-corePoolSize 额外创建的线程等待 keepAliveTime 之后被自动销毁
4.  如果达到 maximumPoolSize，阻塞队列还是满的状态，那么将根据不同的拒绝策略对应处理

![](https://pic4.zhimg.com/v2-fa9b1e08fff8730bcd0ad42a73feb129_r.jpg?source=1940ef5c)

### **拒绝策略有哪些？**

主要有 4 种拒绝策略：

1.  AbortPolicy：直接丢弃任务，抛出异常，这是默认策略
2.  CallerRunsPolicy：只用调用者所在的线程来处理任务
3.  DiscardOldestPolicy：丢弃等待队列中最近的任务，并执行当前任务
4.  DiscardPolicy：直接丢弃任务，也不抛出异常

JVM
---

这是面试专题系列第五篇 JVM 篇。

**说说 JVM 的内存布局？**
-----------------

![](https://pica.zhimg.com/v2-4bdb0e583322be755ad6cb9bea34bb16_r.jpg?source=1940ef5c)

Java 虚拟机主要包含几个区域：

**堆**：堆 Java 虚拟机中最大的一块内存，是线程共享的内存区域，基本上所有的对象实例数组都是在堆上分配空间。堆区细分为 Yound 区年轻代和 Old 区老年代，其中年轻代又分为 Eden、S0、S1 3 个部分，他们默认的比例是 8:1:1 的大小。

**栈**：栈是线程私有的内存区域，每个方法执行的时候都会在栈创建一个栈帧，方法的调用过程就对应着栈的入栈和出栈的过程。每个栈帧的结构又包含局部变量表、操作数栈、动态连接、方法返回地址。

局部变量表用于存储方法参数和局部变量。当第一个方法被调用的时候，他的参数会被传递至从 0 开始的连续的局部变量表中。

操作数栈用于一些字节码指令从局部变量表中传递至操作数栈，也用来准备方法调用的参数以及接收方法返回结果。

动态连接用于将符号引用表示的方法转换为实际方法的直接引用。

**元数据**：在 Java1.7 之前，包含方法区的概念，常量池就存在于方法区（永久代）中，而方法区本身是一个逻辑上的概念，在 1.7 之后则是把常量池移到了堆内，1.8 之后移除了永久代的概念 (方法区的概念仍然保留)，实现方式则是现在的元数据。它包含类的元信息和运行时常量池。

Class 文件就是类和接口的定义信息。

运行时常量池就是类和接口的常量池运行时的表现形式。

**本地方法栈**：主要用于执行本地 native 方法的区域

**程序计数器**：也是线程私有的区域，用于记录当前线程下虚拟机正在执行的字节码的指令地址

**知道 new 一个对象的过程吗？**
--------------------

![](https://pic3.zhimg.com/v2-1dca4788093d90912ba6ce3612fedb0e_r.jpg?source=1940ef5c)

当虚拟机遇见 new 关键字时候，实现判断当前类是否已经加载，如果类没有加载，首先执行类的加载机制，加载完成后再为对象分配空间、初始化等。

1.  首先校验当前类是否被加载，如果没有加载，执行类加载机制
2.  加载：就是从字节码加载成二进制流的过程
3.  验证：当然加载完成之后，当然需要校验 Class 文件是否符合虚拟机规范，跟我们接口请求一样，第一件事情当然是先做个参数校验了
4.  准备：为静态变量、常量赋默认值
5.  解析：把常量池中符号引用 (以符号描述引用的目标) 替换为直接引用 (指向目标的指针或者句柄等) 的过程
6.  初始化：执行 static 代码块 (cinit) 进行初始化，如果存在父类，先对父类进行初始化

_Ps：静态代码块是绝对线程安全的，只能隐式被 java 虚拟机在类加载过程中初始化调用！_(此处该有问题 static 代码块线程安全吗？)

当类加载完成之后，紧接着就是对象分配内存空间和初始化的过程

1.  首先为对象分配合适大小的内存空间
2.  接着为实例变量赋默认值
3.  设置对象的头信息，对象 hash 码、GC 分代年龄、元数据信息等
4.  执行构造函数 (init) 初始化

**知道双亲委派模型吗？**
--------------

类加载器自顶向下分为：

1.  Bootstrap ClassLoader 启动类加载器：默认会去加载 JAVA_HOME/lib 目录下的 jar
2.  Extention ClassLoader 扩展类加载器：默认去加载 JAVA_HOME/lib/ext 目录下的 jar
3.  Application ClassLoader 应用程序类加载器：比如我们的 web 应用，会加载 web 程序中 ClassPath 下的类
4.  User ClassLoader 用户自定义类加载器：由用户自己定义

当我们在加载类的时候，首先都会向上询问自己的父加载器是否已经加载，如果没有则依次向上询问，如果没有加载，则从上到下依次尝试是否能加载当前类，直到加载成功。

![](https://picx.zhimg.com/v2-85641c9fe21430077ffdd71adbb3cb5b_r.jpg?source=1940ef5c)

**说说有哪些垃圾回收算法？**
----------------

### **标记 - 清除**

统一标记出需要回收的对象，标记完成之后统一回收所有被标记的对象，而由于标记的过程需要遍历所有的 GC ROOT，清除的过程也要遍历堆中所有的对象，所以标记 - 清除算法的效率低下，同时也带来了内存碎片的问题。

### **复制算法**

为了解决性能的问题，复制算法应运而生，它将内存分为大小相等的两块区域，每次使用其中的一块，当一块内存使用完之后，将还存活的对象拷贝到另外一块内存区域中，然后把当前内存清空，这样性能和内存碎片的问题得以解决。但是同时带来了另外一个问题，可使用的内存空间缩小了一半！

因此，诞生了我们现在的常见的年轻代 + 老年代的内存结构：Eden+S0+S1 组成，因为根据 IBM 的研究显示，98% 的对象都是朝生夕死，所以实际上存活的对象并不是很多，完全不需要用到一半内存浪费，所以默认的比例是 8:1:1。

这样，在使用的时候只使用 Eden 区和 S0S1 中的一个，每次都把存活的对象拷贝另外一个未使用的 Survivor 区，同时清空 Eden 和使用的 Survivor，这样下来内存的浪费就只有 10% 了。

如果最后未使用的 Survivor 放不下存活的对象，这些对象就进入 Old 老年代了。

_PS：所以有一些初级点的问题会问你为什么要分为 Eden 区和 2 个 Survior 区？有什么作用？就是为了节省内存和解决内存碎片的问题，这些算法都是为了解决问题而产生的，如果理解原因你就不需要死记硬背了_

### **标记 - 整理**

针对老年代再用复制算法显然不合适，因为进入老年代的对象都存活率比较高了，这时候再频繁的复制对性能影响就比较大，而且也不会再有另外的空间进行兜底。所以针对老年代的特点，通过标记 - 整理算法，标记出所有的存活对象，让所有存活的对象都向一端移动，然后清理掉边界以外的内存空间。

**那么什么是 GC ROOT？有哪些 GC ROOT？**
------------------------------

上面提到的标记的算法，怎么标记一个对象是否存活？简单的通过引用计数法，给对象设置一个引用计数器，每当有一个地方引用他，就给计数器 + 1，反之则计数器 - 1，但是这个简单的算法无法解决循环引用的问题。

Java 通过可达性分析算法来达到标记存活对象的目的，定义一系列的 GC ROOT 为起点，从起点开始向下开始搜索，搜索走过的路径称为引用链，当一个对象到 GC ROOT 没有任何引用链相连的话，则对象可以判定是可以被回收的。

而可以作为 GC ROOT 的对象包括：

1.  栈中引用的对象
2.  静态变量、常量引用的对象
3.  本地方法栈 native 方法引用的对象  
    

**垃圾回收器了解吗？年轻代和老年代都有哪些垃圾回收器？**
------------------------------

![](https://pic1.zhimg.com/v2-c91a192ed968ddb4405a73302c4977f7_r.jpg?source=1940ef5c)

年轻代的垃圾收集器包含有 Serial、ParNew、Parallell，老年代则包括 Serial Old 老年代版本、CMS、Parallel Old 老年代版本和 JDK11 中的船新的 G1 收集器。

**Serial**：单线程版本收集器，进行垃圾回收的时候会 STW（Stop The World），也就是进行垃圾回收的时候其他的工作线程都必须暂停

**ParNew**：Serial 的多线程版本，用于和 CMS 配合使用

**Parallel Scavenge**：可以并行收集的多线程垃圾收集器

**Serial Old**：Serial 的老年代版本，也是单线程

**Parallel Old**：Parallel Scavenge 的老年代版本

**CMS（Concurrent Mark Sweep）**：CMS 收集器是以获取最短停顿时间为目标的收集器，相对于其他的收集器 STW 的时间更短暂，可以并行收集是他的特点，同时他基于标记 - 清除算法，整个 GC 的过程分为 4 步。

1.  初始标记：标记 GC ROOT 能关联到的对象，需要 STW
2.  并发标记：从 GCRoots 的直接关联对象开始遍历整个对象图的过程，不需要 STW
3.  重新标记：为了修正并发标记期间，因用户程序继续运作而导致标记产生改变的标记，需要 STW
4.  并发清除：清理删除掉标记阶段判断的已经死亡的对象，不需要 STW

从整个过程来看，并发标记和并发清除的耗时最长，但是不需要停止用户线程，而初始标记和重新标记的耗时较短，但是需要停止用户线程，总体而言，整个过程造成的停顿时间较短，大部分时候是可以和用户线程一起工作的。

**G1（Garbage First）**：G1 收集器是 JDK9 的默认垃圾收集器，而且不再区分年轻代和老年代进行回收。

**G1 的原理了解吗？**
--------------

![](https://pic1.zhimg.com/v2-496bba2300639fd8e799b14f0e2c35d7_r.jpg?source=1940ef5c)

G1 作为 JDK9 之后的服务端默认收集器，且不再区分年轻代和老年代进行垃圾回收，他把内存划分为多个 Region，每个 Region 的大小可以通过 - XX：G1HeapRegionSize 设置，大小为 1~32M，对于大对象的存储则衍生出 Humongous 的概念，超过 Region 大小一半的对象会被认为是大对象，而超过整个 Region 大小的对象被认为是超级大对象，将会被存储在连续的 N 个 Humongous Region 中，G1 在进行回收的时候会在后台维护一个优先级列表，每次根据用户设定允许的收集停顿时间优先回收收益最大的 Region。

G1 的回收过程分为以下四个步骤：

1.  初始标记：标记 GC ROOT 能关联到的对象，需要 STW
2.  并发标记：从 GCRoots 的直接关联对象开始遍历整个对象图的过程，扫描完成后还会重新处理并发标记过程中产生变动的对象
3.  最终标记：短暂暂停用户线程，再处理一次，需要 STW
4.  筛选回收：更新 Region 的统计数据，对每个 Region 的回收价值和成本排序，根据用户设置的停顿时间制定回收计划。再把需要回收的 Region 中存活对象复制到空的 Region，同时清理旧的 Region。需要 STW

总的来说除了并发标记之外，其他几个过程也还是需要短暂的 STW，G1 的目标是在停顿和延迟可控的情况下尽可能提高吞吐量。

**什么时候会触发 YGC 和 FGC？对象什么时候会进入老年代？**
-----------------------------------

当一个新的对象来申请内存空间的时候，如果 Eden 区无法满足内存分配需求，则触发 YGC，使用中的 Survivor 区和 Eden 区存活对象送到未使用的 Survivor 区，如果 YGC 之后还是没有足够空间，则直接进入老年代分配，如果老年代也无法分配空间，触发 FGC，FGC 之后还是放不下则报出 OOM 异常。

![](https://pica.zhimg.com/v2-b7d8c7af9bdce18027aa07c8958d6a95_r.jpg?source=1940ef5c)

YGC 之后，存活的对象将会被复制到未使用的 Survivor 区，如果 S 区放不下，则直接晋升至老年代。而对于那些一直在 Survivor 区来回复制的对象，通过 - XX：MaxTenuringThreshold 配置交换阈值，默认 15 次，如果超过次数同样进入老年代。

此外，还有一种动态年龄的判断机制，不需要等到 MaxTenuringThreshold 就能晋升老年代。如果在 Survivor 空间中相同年龄所有对象大小的总和大于 Survivor 空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代。

**频繁 FullGC 怎么排查？**
-------------------

这种问题最好的办法就是结合有具体的例子举例分析，如果没有就说一般的分析步骤。发生 FGC 有可能是内存分配不合理，比如 Eden 区太小，导致对象频繁进入老年代，这时候通过启动参数配置就能看出来，另外有可能就是存在内存泄露，可以通过以下的步骤进行排查：

1.  jstat -gcutil 或者查看 gc.log 日志，查看内存回收情况

![](https://picx.zhimg.com/v2-ca4d502917b7bb6ebc591642101d2954_r.jpg?source=1940ef5c)

S0 S1 分别代表两个 Survivor 区占比

E 代表 Eden 区占比，图中可以看到使用 78%

O 代表老年代，M 代表元空间，YGC 发生 54 次，YGCT 代表 YGC 累计耗时，GCT 代表 GC 累计耗时。

![](https://pica.zhimg.com/v2-ef25f0a5fc12f336f900bf360600c735_r.jpg?source=1940ef5c)

[GC [FGC 开头代表垃圾回收的类型

PSYoungGen: 6130K->6130K(9216K)] 12274K->14330K(19456K), 0.0034895 secs 代表 YGC 前后内存使用情况

Times: user=0.02 sys=0.00, real=0.00 secs，user 表示用户态消耗的 CPU 时间，sys 表示内核态消耗的 CPU 时间，real 表示各种墙时钟的等待时间

这两张图只是举例并没有关联关系，比如你从图里面看能到是否进行 FGC，FGC 的时间花费多长，GC 后老年代，年轻代内存是否有减少，得到一些初步的情况来做出判断。

1.  dump 出内存文件再具体分析，比如通过 jmap 命令 jmap -dump:format=b,file=dumpfile pid，导出之后再通过 **Eclipse Memory Analyzer** 等工具进行分析，定位到代码，修复

这里还会可能存在一个提问的点，比如 CPU 飙高，同时 FGC 怎么办？办法比较类似

1.  找到当前进程的 pid，top -p pid -H 查看资源占用，找到线程
2.  printf “%x\n” pid，把线程 pid 转为 16 进制，比如 0x32d
3.  jstack pid|grep -A 10 0x32d 查看线程的堆栈日志，还找不到问题继续
4.  dump 出内存文件用 MAT 等工具进行分析，定位到代码，修复

**JVM 调优有什么经验吗？**
-----------------

要明白一点，所有的调优的目的都是为了用更小的硬件成本达到更高的吞吐，JVM 的调优也是一样，通过对垃圾收集器和内存分配的调优达到性能的最佳。

### **简单的参数含义**

首先，需要知道几个主要的参数含义。

![](https://pic1.zhimg.com/v2-9f34b2a4c99ebe1cbd440215582b8f72_r.jpg?source=1940ef5c)

1.  -Xms 设置初始堆的大小，-Xmx 设置最大堆的大小
2.  -XX:NewSize 年轻代大小，-XX:MaxNewSize 年轻代最大值，-Xmn 则是相当于同时配置 - XX:NewSize 和 - XX:MaxNewSize 为一样的值
3.  -XX:NewRatio 设置年轻代和年老代的比值，如果为 3，表示年轻代与老年代比值为 1:3，默认值为 2
4.  -XX:SurvivorRatio 年轻代和两个 Survivor 的比值，默认 8，代表比值为 8:1:1
5.  -XX:PretenureSizeThreshold 当创建的对象超过指定大小时，直接把对象分配在老年代。
6.  -XX:MaxTenuringThreshold 设定对象在 Survivor 复制的最大年龄阈值，超过阈值转移到老年代
7.  -XX:MaxDirectMemorySize 当 Direct ByteBuffer 分配的堆外内存到达指定大小后，即触发 Full GC

### **调优**

1.  为了打印日志方便排查问题最好开启 GC 日志，开启 GC 日志对性能影响微乎其微，但是能帮助我们快速排查定位问题。-XX:+PrintGCTimeStamps -XX:+PrintGCDetails -Xloggc:gc.log
2.  一般设置 - Xms=-Xmx，这样可以获得固定大小的堆内存，减少 GC 的次数和耗时，可以使得堆相对稳定
3.  -XX:+HeapDumpOnOutOfMemoryError 让 JVM 在发生内存溢出的时候自动生成内存快照，方便排查问题
4.  -Xmn 设置年轻代的大小，太小会增加 YGC，太大会减小老年代大小，一般设置为整个堆的 1/4 到 1/3
5.  设置 - XX:+DisableExplicitGC 禁止系统 System.gc()，防止手动误触发 FGC 造成问题

Mysql
-----

想进大厂，mysql 不会那可不行，来接受 mysql 面试挑战吧，看看你能坚持到哪里？

### **1. 能说下 myisam 和 innodb 的区别吗？**

myisam 引擎是 5.1 版本之前的默认引擎，支持全文检索、压缩、空间函数等，但是不支持事务和行级锁，所以一般用于有大量查询少量插入的场景来使用，而且 myisam 不支持外键，并且索引和数据是分开存储的。

innodb 是基于聚簇索引建立的，和 myisam 相反它支持事务、外键，并且通过 MVCC 来支持高并发，索引和数据存储在一起。

### **2. 说下 mysql 的索引有哪些吧，聚簇和非聚簇索引又是什么？**

索引按照数据结构来说主要包含 B + 树和 Hash 索引。

假设我们有张表，结构如下：

```
create table user(
  id int(11) not null,
  age int(11) not null,
  primary key(id),
  key(age)
);
```

B + 树是左小右大的顺序存储结构，节点只包含 id 索引列，而叶子节点包含索引列和数据，这种数据和索引在一起存储的索引方式叫做聚簇索引，一张表只能有一个聚簇索引。假设没有定义主键，InnoDB 会选择一个唯一的非空索引代替，如果没有的话则会隐式定义一个主键作为聚簇索引。

![](https://pic4.zhimg.com/v2-bafac0872e81d3c786ff0f8152b7e98b_r.jpg?source=1940ef5c)

这是主键聚簇索引存储的结构，那么非聚簇索引的结构是什么样子呢？非聚簇索引 (二级索引) 保存的是主键 id 值，这一点和 myisam 保存的是数据地址是不同的。

![](https://pic3.zhimg.com/v2-b36c1bd75165e50522a5e8b0caf0f9c9_r.jpg?source=1940ef5c)

最终，我们一张图看看 InnoDB 和 Myisam 聚簇和非聚簇索引的区别

![](https://pic2.zhimg.com/v2-197c55fed2cb8d8e3dae118c7b75d3b2_r.jpg?source=1940ef5c)

### **3. 那你知道什么是覆盖索引和回表吗？**

覆盖索引指的是在一次查询中，如果一个索引包含或者说覆盖所有需要查询的字段的值，我们就称之为覆盖索引，而不再需要回表查询。

而要确定一个查询是否是覆盖索引，我们只需要 explain sql 语句看 Extra 的结果是否是 “Using index” 即可。

以上面的 user 表来举例，我们再增加一个 name 字段，然后做一些查询试试。

```
explain select * from user where age=1; //查询的name无法从索引数据获取
explain select id,age from user where age=1; //可以直接从索引获取
```

### **4. 锁的类型有哪些呢**

mysql 锁分为**共享锁**和**排他锁**，也叫做读锁和写锁。

读锁是共享的，可以通过 lock in share mode 实现，这时候只能读不能写。

写锁是排他的，它会阻塞其他的写锁和读锁。从颗粒度来区分，可以分为**表锁**和**行锁**两种。

表锁会锁定整张表并且阻塞其他用户对该表的所有读写操作，比如 alter 修改表结构的时候会锁表。

行锁又可以分为**乐观锁**和**悲观锁**，悲观锁可以通过 for update 实现，乐观锁则通过版本号实现。

### **5. 你能说下事务的基本特性和隔离级别吗？**

事务基本特性 ACID 分别是：

**原子性**指的是一个事务中的操作要么全部成功，要么全部失败。

**一致性**指的是数据库总是从一个一致性的状态转换到另外一个一致性的状态。比如 A 转账给 B100 块钱，假设中间 sql 执行过程中系统崩溃 A 也不会损失 100 块，因为事务没有提交，修改也就不会保存到数据库。

**隔离性**指的是一个事务的修改在最终提交前，对其他事务是不可见的。

**持久性**指的是一旦事务提交，所做的修改就会永久保存到数据库中。

而隔离性有 4 个隔离级别，分别是：

**read uncommit** 读未提交，可能会读到其他事务未提交的数据，也叫做脏读。

用户本来应该读取到 id=1 的用户 age 应该是 10，结果读取到了其他事务还没有提交的事务，结果读取结果 age=20，这就是脏读。

![](https://pic1.zhimg.com/v2-593fbcf68e09e8864d7205028f47b681_r.jpg?source=1940ef5c)

**read commit** 读已提交，两次读取结果不一致，叫做不可重复读。

不可重复读解决了脏读的问题，他只会读取已经提交的事务。

用户开启事务读取 id=1 用户，查询到 age=10，再次读取发现结果 = 20，在同一个事务里同一个查询读取到不同的结果叫做不可重复读。

![](https://pic1.zhimg.com/v2-709b3f048ebc3ffc32da906c3e8965d3_r.jpg?source=1940ef5c)

**repeatable read** 可重复复读，这是 mysql 的默认级别，就是每次读取结果都一样，但是有可能产生幻读。

**serializable** 串行，一般是不会使用的，他会给每一行读取的数据加锁，会导致大量超时和锁竞争的问题。

### **6. 那 ACID 靠什么保证的呢？**

A 原子性由 undo log 日志保证，它记录了需要回滚的日志信息，事务回滚时撤销已经执行成功的 sql

C 一致性一般由代码层面来保证

I 隔离性由 MVCC 来保证

D 持久性由内存 + redo log 来保证，mysql 修改数据同时在内存和 redo log 记录这次操作，事务提交的时候通过 redo log 刷盘，宕机的时候可以从 redo log 恢复

### **7. 那你说说什么是幻读，什么是 MVCC？**

要说幻读，首先要了解 MVCC，MVCC 叫做多版本并发控制，实际上就是保存了数据在某个时间节点的快照。

我们每行数据实际上隐藏了两列，创建时间版本号，过期 (删除) 时间版本号，每开始一个新的事务，版本号都会自动递增。

还是拿上面的 user 表举例子，假设我们插入两条数据，他们实际上应该长这样。

<table data-draft-node="block" data-draft-type="table" data-size="normal"><tbody><tr><th>id</th><th>name</th><th>create_version</th><th>delete_version</th></tr></tbody></table>

这时候假设小明去执行查询，此时 current_version=3

```
select * from user where id<=3;
```

同时，小红在这时候开启事务去修改 id=1 的记录，current_version=4

```
update user set name='张三三' where id=1;
```

执行成功后的结果是这样的

<table data-draft-node="block" data-draft-type="table" data-size="normal"><tbody><tr><th>id</th><th>name</th><th>create_version</th><th>delete_version</th></tr></tbody></table>

如果这时候还有小黑在删除 id=2 的数据，current_version=5，执行后结果是这样的。

<table data-draft-node="block" data-draft-type="table" data-size="normal"><tbody><tr><th>id</th><th>name</th><th>create_version</th><th>delete_version</th></tr></tbody></table>

由于 MVCC 的原理是查找创建版本小于或等于当前事务版本，删除版本为空或者大于当前事务版本，小明的真实的查询应该是这样

```
select * from user where id<=3 and create_version<=3 and (delete_version>3 or delete_version is null);
```

所以小明最后查询到的 id=1 的名字还是'张三'，并且 id=2 的记录也能查询到。这样做是**为了保证事务读取的数据是在事务开始前就已经存在的，要么是事务自己插入或者修改的**。

明白 MVCC 原理，我们来说什么是幻读就简单多了。举一个常见的场景，用户注册时，我们先查询用户名是否存在，不存在就插入，假定用户名是唯一索引。

1.  小明开启事务 current_version=6 查询名字为'王五'的记录，发现不存在。
2.  小红开启事务 current_version=7 插入一条数据，结果是这样：

<table data-draft-node="block" data-draft-type="table" data-size="normal"><tbody><tr><th>id</th><th>Name</th><th>create_version</th><th>delete_version</th></tr></tbody></table>

1.  小明执行插入名字'王五'的记录，发现唯一索引冲突，无法插入，这就是幻读。

### **8. 那你知道什么是间隙锁吗？**

间隙锁是可重复读级别下才会有的锁，结合 MVCC 和间隙锁可以解决幻读的问题。我们还是以 user 举例，假设现在 user 表有几条记录

<table data-draft-node="block" data-draft-type="table" data-size="normal"><tbody><tr><th>id</th><th>Age</th></tr></tbody></table>

当我们执行：

```
begin;
select * from user where age=20 for update;
​
begin;
insert into user(age) values(10); #成功
insert into user(age) values(11); #失败
insert into user(age) values(20); #失败
insert into user(age) values(21); #失败
insert into user(age) values(30); #失败
```

只有 10 可以插入成功，那么因为表的间隙 mysql 自动帮我们生成了区间 (左开右闭)

```
(negative infinity，10],(10,20],(20,30],(30,positive infinity)
```

由于 20 存在记录，所以 (10,20]，(20,30] 区间都被锁定了无法插入、删除。

如果查询 21 呢？就会根据 21 定位到 (20,30) 的区间(都是开区间)。

需要注意的是唯一索引是不会有间隙索引的。

### **9. 你们数据量级多大？分库分表怎么做的？**

首先分库分表分为垂直和水平两个方式，一般来说我们拆分的顺序是先垂直后水平。

**垂直分库**

基于现在微服务拆分来说，都是已经做到了垂直分库了

![](https://pic1.zhimg.com/v2-1d23874d7a8170ab2e215217beba7295_r.jpg?source=1940ef5c)

**垂直分表**

如果表字段比较多，将不常用的、数据较大的等等做拆分

![](https://pica.zhimg.com/v2-159edd1d848f4e6567ffa8c80e5010a8_r.jpg?source=1940ef5c)

**水平分表**

首先根据业务场景来决定使用什么字段作为分表字段 (sharding_key)，比如我们现在日订单 1000 万，我们大部分的场景来源于 C 端，我们可以用 user_id 作为 sharding_key，数据查询支持到最近 3 个月的订单，超过 3 个月的做归档处理，那么 3 个月的数据量就是 9 亿，可以分 1024 张表，那么每张表的数据大概就在 100 万左右。

比如用户 id 为 100，那我们都经过 hash(100)，然后对 1024 取模，就可以落到对应的表上了。

### **10. 那分表后的 ID 怎么保证唯一性的呢？**

因为我们主键默认都是自增的，那么分表之后的主键在不同表就肯定会有冲突了。有几个办法考虑：

1.  设定步长，比如 1-1024 张表我们设定 1024 的基础步长，这样主键落到不同的表就不会冲突了。
2.  分布式 ID，自己实现一套分布式 ID 生成算法或者使用开源的比如雪花算法这种
3.  分表后不使用主键作为查询依据，而是每张表单独新增一个字段作为唯一主键使用，比如订单表订单号是唯一的，不管最终落在哪张表都基于订单号作为查询依据，更新也一样。

### **11. 分表后非 sharding_key 的查询怎么处理呢？**

1.  可以做一个 mapping 表，比如这时候商家要查询订单列表怎么办呢？不带 user_id 查询的话你总不能扫全表吧？所以我们可以做一个映射关系表，保存商家和用户的关系，查询的时候先通过商家查询到用户列表，再通过 user_id 去查询。
2.  打宽表，一般而言，商户端对数据实时性要求并不是很高，比如查询订单列表，可以把订单表同步到离线（实时）数仓，再基于数仓去做成一张宽表，再基于其他如 es 提供查询服务。
3.  数据量不是很大的话，比如后台的一些查询之类的，也可以通过多线程扫表，然后再聚合结果的方式来做。或者异步的形式也是可以的。

```
List<Callable<List<User>>> taskList = Lists.newArrayList();
for (int shardingIndex = 0; shardingIndex < 1024; shardingIndex++) {
    taskList.add(() -> (userMapper.getProcessingAccountList(shardingIndex)));
}
List<ThirdAccountInfo> list = null;
try {
    list = taskExecutor.executeTask(taskList);
} catch (Exception e) {
    //do something
}
​
public class TaskExecutor {
    public <T> List<T> executeTask(Collection<? extends Callable<T>> tasks) throws Exception {
        List<T> result = Lists.newArrayList();
        List<Future<T>> futures = ExecutorUtil.invokeAll(tasks);
        for (Future<T> future : futures) {
            result.add(future.get());
        }
        return result;
    }
}
```

### **12. 说说 mysql 主从同步怎么做的吧？**

首先先了解 mysql 主从同步的原理

1.  master 提交完事务后，写入 binlog
2.  slave 连接到 master，获取 binlog
3.  master 创建 dump 线程，推送 binglog 到 slave
4.  slave 启动一个 IO 线程读取同步过来的 master 的 binlog，记录到 relay log 中继日志中
5.  slave 再开启一个 sql 线程读取 relay log 事件并在 slave 执行，完成同步
6.  slave 记录自己的 binglog

![](https://pic3.zhimg.com/v2-02d5e7feecf8d1ad1afb8d84a9204489_r.jpg?source=1940ef5c)

由于 mysql 默认的复制方式是异步的，主库把日志发送给从库后不关心从库是否已经处理，这样会产生一个问题就是假设主库挂了，从库处理失败了，这时候从库升为主库后，日志就丢失了。由此产生两个概念。

**全同步复制**

主库写入 binlog 后强制同步日志到从库，所有的从库都执行完成后才返回给客户端，但是很显然这个方式的话性能会受到严重影响。

**半同步复制**

和全同步不同的是，半同步复制的逻辑是这样，从库写入日志成功后返回 ACK 确认给主库，主库收到至少一个从库的确认就认为写操作完成。

### **13. 那主从的延迟怎么解决呢？**

1.  针对特定的业务场景，读写请求都强制走主库
2.  读请求走从库，如果没有数据，去主库做二次查询

Redis
-----

这是面试题系列第三篇 --redis 专题。

**说说 Redis 基本数据类型有哪些吧**
-----------------------

1.  字符串：redis 没有直接使用 C 语言传统的字符串表示，而是自己实现的叫做简单动态字符串 SDS 的抽象类型。C 语言的字符串不记录自身的长度信息，而 SDS 则保存了长度信息，这样将获取字符串长度的时间由 O(N) 降低到了 O(1)，同时可以避免缓冲区溢出和减少修改字符串长度时所需的内存重分配次数。
2.  链表 linkedlist：redis 链表是一个双向无环链表结构，很多发布订阅、慢查询、监视器功能都是使用到了链表来实现，每个链表的节点由一个 listNode 结构来表示，每个节点都有指向前置节点和后置节点的指针，同时表头节点的前置和后置节点都指向 NULL。
3.  字典 hashtable：用于保存键值对的抽象数据结构。redis 使用 hash 表作为底层实现，每个字典带有两个 hash 表，供平时使用和 rehash 时使用，hash 表使用链地址法来解决键冲突，被分配到同一个索引位置的多个键值对会形成一个单向链表，在对 hash 表进行扩容或者缩容的时候，为了服务的可用性，rehash 的过程不是一次性完成的，而是渐进式的。
4.  跳跃表 skiplist：跳跃表是有序集合的底层实现之一，redis 中在实现有序集合键和集群节点的内部结构中都是用到了跳跃表。redis 跳跃表由 zskiplist 和 zskiplistNode 组成，zskiplist 用于保存跳跃表信息（表头、表尾节点、长度等），zskiplistNode 用于表示表跳跃节点，每个跳跃表的层高都是 1-32 的随机数，在同一个跳跃表中，多个节点可以包含相同的分值，但是每个节点的成员对象必须是唯一的，节点按照分值大小排序，如果分值相同，则按照成员对象的大小排序。
5.  整数集合 intset：用于保存整数值的集合抽象数据结构，不会出现重复元素，底层实现为数组。
6.  压缩列表 ziplist：压缩列表是为节约内存而开发的顺序性数据结构，他可以包含多个节点，每个节点可以保存一个字节数组或者整数值。

基于这些基础的数据结构，redis 封装了自己的对象系统，包含字符串对象 string、列表对象 list、哈希对象 hash、集合对象 set、有序集合对象 zset，每种对象都用到了至少一种基础的数据结构。

redis 通过 encoding 属性设置对象的编码形式来提升灵活性和效率，基于不同的场景 redis 会自动做出优化。不同对象的编码如下：

1.  字符串对象 string：int 整数、embstr 编码的简单动态字符串、raw 简单动态字符串
2.  列表对象 list：ziplist、linkedlist
3.  哈希对象 hash：ziplist、hashtable
4.  集合对象 set：intset、hashtable
5.  有序集合对象 zset：ziplist、skiplist

**Redis 为什么快呢？**
----------------

redis 的速度非常的快，单机的 redis 就可以支撑每秒 10 几万的并发，相对于 mysql 来说，性能是 mysql 的几十倍。速度快的原因主要有几点：

1.  完全基于内存操作
2.  C 语言实现，优化过的数据结构，基于几种基础的数据结构，redis 做了大量的优化，性能极高
3.  使用单线程，无上下文的切换成本
4.  基于非阻塞的 IO 多路复用机制

**那为什么 Redis6.0 之后又改用多线程呢?**
----------------------------

redis 使用多线程并非是完全摒弃单线程，redis 还是使用单线程模型来处理客户端的请求，只是使用多线程来处理数据的读写和协议解析，执行命令还是使用单线程。

这样做的目的是因为 redis 的性能瓶颈在于网络 IO 而非 CPU，使用多线程能提升 IO 读写的效率，从而整体提高 redis 的性能。

**知道什么是热 key 吗？热 key 问题怎么解决？**
------------------------------

所谓热 key 问题就是，突然有几十万的请求去访问 redis 上的某个特定 key，那么这样会造成流量过于集中，达到物理网卡上限，从而导致这台 redis 的服务器宕机引发雪崩。

![](https://pic2.zhimg.com/v2-cfaff983f1a3df3009bf515a396508ea_r.jpg?source=1940ef5c)

针对热 key 的解决方案：

1.  提前把热 key 打散到不同的服务器，降低压力
2.  加入二级缓存，提前加载热 key 数据到内存中，如果 redis 宕机，走内存查询

**什么是缓存击穿、缓存穿透、缓存雪崩？**
----------------------

**缓存击穿**
--------

缓存击穿的概念就是单个 key 并发访问过高，过期时导致所有请求直接打到 db 上，这个和热 key 的问题比较类似，只是说的点在于过期导致请求全部打到 DB 上而已。

解决方案：

1.  加锁更新，比如请求查询 A，发现缓存中没有，对 A 这个 key 加锁，同时去数据库查询数据，写入缓存，再返回给用户，这样后面的请求就可以从缓存中拿到数据了。
2.  将过期时间组合写在 value 中，通过异步的方式不断的刷新过期时间，防止此类现象。

![](https://pica.zhimg.com/v2-e7dab2091bcae52fb6c8a8c7b5cd171e_r.jpg?source=1940ef5c)

[https://tva](https://link.zhihu.com/?target=https%3A//tva/)

**缓存穿透**
--------

缓存穿透是指查询不存在缓存中的数据，每次请求都会打到 DB，就像缓存不存在一样。

![](https://pica.zhimg.com/v2-4d21f8fb7e1b253444d7c44533c8be9e_r.jpg?source=1940ef5c)

针对这个问题，加一层布隆过滤器。布隆过滤器的原理是在你存入数据的时候，会通过散列函数将它映射为一个位数组中的 K 个点，同时把他们置为 1。

这样当用户再次来查询 A，而 A 在布隆过滤器值为 0，直接返回，就不会产生击穿请求打到 DB 了。

显然，使用布隆过滤器之后会有一个问题就是误判，因为它本身是一个数组，可能会有多个值落到同一个位置，那么理论上来说只要我们的数组长度够长，误判的概率就会越低，这种问题就根据实际情况来就好了。

![](https://pica.zhimg.com/v2-4c94ede88b2313f1d8fe42aaf876933e_r.jpg?source=1940ef5c)

**缓存雪崩**
--------

当某一时刻发生大规模的缓存失效的情况，比如你的缓存服务宕机了，会有大量的请求进来直接打到 DB 上，这样可能导致整个系统的崩溃，称为雪崩。雪崩和击穿、热 key 的问题不太一样的是，他是指大规模的缓存都过期失效了。

![](https://pic1.zhimg.com/v2-8a6e9464f160d29ceef4049eeeb4af17_r.jpg?source=1940ef5c)

针对雪崩几个解决方案：

1.  针对不同 key 设置不同的过期时间，避免同时过期
2.  限流，如果 redis 宕机，可以限流，避免同时刻大量请求打崩 DB
3.  二级缓存，同热 key 的方案。

**Redis 的过期策略有哪些？**
-------------------

redis 主要有 2 种过期删除策略

**惰性删除**
--------

惰性删除指的是当我们查询 key 的时候才对 key 进行检测，如果已经达到过期时间，则删除。显然，他有一个缺点就是如果这些过期的 key 没有被访问，那么他就一直无法被删除，而且一直占用内存。

![](https://pic4.zhimg.com/v2-769e4b145d03c4d407cff2d6bb9669a1_r.jpg?source=1940ef5c)

**定期删除**
--------

定期删除指的是 redis 每隔一段时间对数据库做一次检查，删除里面的过期 key。由于不可能对所有 key 去做轮询来删除，所以 redis 会每次随机取一些 key 去做检查和删除。

**那么定期 + 惰性都没有删除过期的 key 怎么办？**
------------------------------

假设 redis 每次定期随机查询 key 的时候没有删掉，这些 key 也没有做查询的话，就会导致这些 key 一直保存在 redis 里面无法被删除，这时候就会走到 redis 的内存淘汰机制。

1.  volatile-lru：从已设置过期时间的 key 中，移除最近最少使用的 key 进行淘汰
2.  volatile-ttl：从已设置过期时间的 key 中，移除将要过期的 key
3.  volatile-random：从已设置过期时间的 key 中随机选择 key 淘汰
4.  allkeys-lru：从 key 中选择最近最少使用的进行淘汰
5.  allkeys-random：从 key 中随机选择 key 进行淘汰
6.  noeviction：当内存达到阈值的时候，新写入操作报错

**持久化方式有哪些？有什么区别？**
-------------------

redis 持久化方案分为 RDB 和 AOF 两种。

**RDB**
-------

RDB 持久化可以手动执行也可以根据配置定期执行，它的作用是将某个时间点上的数据库状态保存到 RDB 文件中，RDB 文件是一个压缩的二进制文件，通过它可以还原某个时刻数据库的状态。由于 RDB 文件是保存在硬盘上的，所以即使 redis 崩溃或者退出，只要 RDB 文件存在，就可以用它来恢复还原数据库的状态。

可以通过 SAVE 或者 BGSAVE 来生成 RDB 文件。

SAVE 命令会阻塞 redis 进程，直到 RDB 文件生成完毕，在进程阻塞期间，redis 不能处理任何命令请求，这显然是不合适的。

BGSAVE 则是会 fork 出一个子进程，然后由子进程去负责生成 RDB 文件，父进程还可以继续处理命令请求，不会阻塞进程。

**AOF**
-------

AOF 和 RDB 不同，AOF 是通过保存 redis 服务器所执行的写命令来记录数据库状态的。

AOF 通过追加、写入、同步三个步骤来实现持久化机制。

1.  当 AOF 持久化处于激活状态，服务器执行完写命令之后，写命令将会被追加 append 到 aof_buf 缓冲区的末尾
2.  在服务器每结束一个事件循环之前，将会调用 flushAppendOnlyFile 函数决定是否要将 aof_buf 的内容保存到 AOF 文件中，可以通过配置 appendfsync 来决定。

```
always ##aof_buf内容写入并同步到AOF文件
everysec ##将aof_buf中内容写入到AOF文件，如果上次同步AOF文件时间距离现在超过1秒，则再次对AOF文件进行同步
no ##将aof_buf内容写入AOF文件，但是并不对AOF文件进行同步，同步时间由操作系统决定
```

如果不设置，默认选项将会是 everysec，因为 always 来说虽然最安全（只会丢失一次事件循环的写命令），但是性能较差，而 everysec 模式只不过会可能丢失 1 秒钟的数据，而 no 模式的效率和 everysec 相仿，但是会丢失上次同步 AOF 文件之后的所有写命令数据。

**怎么实现 Redis 的高可用？**
--------------------

要想实现高可用，一台机器肯定是不够的，而 redis 要保证高可用，有 2 个可选方案。

**主从架构**
--------

主从模式是最简单的实现高可用的方案，核心就是主从同步。主从同步的原理如下：

1.  slave 发送 sync 命令到 master
2.  master 收到 sync 之后，执行 bgsave，生成 RDB 全量文件
3.  master 把 slave 的写命令记录到缓存
4.  bgsave 执行完毕之后，发送 RDB 文件到 slave，slave 执行
5.  master 发送缓存中的写命令到 slave，slave 执行

![](https://pica.zhimg.com/v2-651f481cae4af3d49266d5e599cc17c0_r.jpg?source=1940ef5c)

这里我写的这个命令是 sync，但是在 redis2.8 版本之后已经使用 psync 来替代 sync 了，原因是 sync 命令非常消耗系统资源，而 psync 的效率更高。

**哨兵**
------

基于主从方案的缺点还是很明显的，假设 master 宕机，那么就不能写入数据，那么 slave 也就失去了作用，整个架构就不可用了，除非你手动切换，主要原因就是因为没有自动故障转移机制。而哨兵 (sentinel) 的功能比单纯的主从架构全面的多了，它具备自动故障转移、集群监控、消息通知等功能。

![](https://pic3.zhimg.com/v2-d394ded4eed2c852ae2a57f3b47498e4_r.jpg?source=1940ef5c)

哨兵可以同时监视多个主从服务器，并且在被监视的 master 下线时，自动将某个 slave 提升为 master，然后由新的 master 继续接收命令。整个过程如下：

1.  初始化 sentinel，将普通的 redis 代码替换成 sentinel 专用代码
2.  初始化 masters 字典和服务器信息，服务器信息主要保存 ip:port，并记录实例的地址和 ID
3.  创建和 master 的两个连接，命令连接和订阅连接，并且订阅 sentinel:hello 频道
4.  每隔 10 秒向 master 发送 info 命令，获取 master 和它下面所有 slave 的当前信息
5.  当发现 master 有新的 slave 之后，sentinel 和新的 slave 同样建立两个连接，同时每个 10 秒发送 info 命令，更新 master 信息
6.  sentinel 每隔 1 秒向所有服务器发送 ping 命令，如果某台服务器在配置的响应时间内连续返回无效回复，将会被标记为下线状态
7.  选举出领头 sentinel，领头 sentinel 需要半数以上的 sentinel 同意
8.  领头 sentinel 从已下线的的 master 所有 slave 中挑选一个，将其转换为 master
9.  让所有的 slave 改为从新的 master 复制数据
10.  将原来的 master 设置为新的 master 的从服务器，当原来 master 重新回复连接时，就变成了新 master 的从服务器

sentinel 会每隔 1 秒向所有实例（包括主从服务器和其他 sentinel）发送 ping 命令，并且根据回复判断是否已经下线，这种方式叫做主观下线。当判断为主观下线时，就会向其他监视的 sentinel 询问，如果超过半数的投票认为已经是下线状态，则会标记为客观下线状态，同时触发故障转移。

**能说说 redis 集群的原理吗？**
---------------------

如果说依靠哨兵可以实现 redis 的高可用，如果还想在支持高并发同时容纳海量的数据，那就需要 redis 集群。redis 集群是 redis 提供的分布式数据存储方案，集群通过数据分片 sharding 来进行数据的共享，同时提供复制和故障转移的功能。

**节点**
------

一个 redis 集群由多个节点 node 组成，而多个 node 之间通过 cluster meet 命令来进行连接，节点的握手过程：

1.  节点 A 收到客户端的 cluster meet 命令
2.  A 根据收到的 IP 地址和端口号，向 B 发送一条 meet 消息
3.  节点 B 收到 meet 消息返回 pong
4.  A 知道 B 收到了 meet 消息，返回一条 ping 消息，握手成功
5.  最后，节点 A 将会通过 gossip 协议把节点 B 的信息传播给集群中的其他节点，其他节点也将和 B 进行握手

![](https://pic2.zhimg.com/v2-38c1de33be6e552a446503cd213d9413_r.jpg?source=1940ef5c)

**槽 slot**
----------

redis 通过集群分片的形式来保存数据，整个集群数据库被分为 16384 个 slot，集群中的每个节点可以处理 0-16383 个 slot，当数据库 16384 个 slot 都有节点在处理时，集群处于上线状态，反之只要有一个 slot 没有得到处理都会处理下线状态。通过 cluster addslots 命令可以将 slot 指派给对应节点处理。

slot 是一个位数组，数组的长度是 16384/8=2048，而数组的每一位用 1 表示被节点处理，0 表示不处理，如图所示的话表示 A 节点处理 0-7 的 slot。

![](https://pic3.zhimg.com/v2-dd6b412af5dcaaa670b51ee67b7668c5_r.jpg?source=1940ef5c)

当客户端向节点发送命令，如果刚好找到 slot 属于当前节点，那么节点就执行命令，反之，则会返回一个 MOVED 命令到客户端指引客户端转向正确的节点。（MOVED 过程是自动的）

![](https://pic2.zhimg.com/v2-226271db384cb106fa4c9bb1b385fe0d_r.jpg?source=1940ef5c)

如果增加或者移出节点，对于 slot 的重新分配也是非常方便的，redis 提供了工具帮助实现 slot 的迁移，整个过程是完全在线的，不需要停止服务。

**故障转移**
--------

如果节点 A 向节点 B 发送 ping 消息，节点 B 没有在规定的时间内响应 pong，那么节点 A 会标记节点 B 为 pfail 疑似下线状态，同时把 B 的状态通过消息的形式发送给其他节点，如果超过半数以上的节点都标记 B 为 pfail 状态，B 就会被标记为 fail 下线状态，此时将会发生故障转移，优先从复制数据较多的从节点选择一个成为主节点，并且接管下线节点的 slot，整个过程和哨兵非常类似，都是基于 Raft 协议做选举。

**了解 Redis 事务机制吗？**
-------------------

redis 通过 MULTI、EXEC、WATCH 等命令来实现事务机制，事务执行过程将一系列多个命令按照顺序一次性执行，并且在执行期间，事务不会被中断，也不会去执行客户端的其他请求，直到所有命令执行完毕。事务的执行过程如下：

1.  服务端收到客户端请求，事务以 MULTI 开始
2.  如果客户端正处于事务状态，则会把事务放入队列同时返回给客户端 QUEUED，反之则直接执行这个命令
3.  当收到客户端 EXEC 命令时，WATCH 命令监视整个事务中的 key 是否有被修改，如果有则返回空回复到客户端表示失败，否则 redis 会遍历整个事务队列，执行队列中保存的所有命令，最后返回结果给客户端

WATCH 的机制本身是一个 CAS 的机制，被监视的 key 会被保存到一个链表中，如果某个 key 被修改，那么 REDIS_DIRTY_CAS 标志将会被打开，这时服务器会拒绝执行事务。

MQ
--

继之前的 mysql 夺命连环之后，我发现我这个标题被好多套用的，什么夺命 zookeeper，夺命多线程一大堆，这一次，开始面试题系列 MQ 专题，消息队列作为日常常见的使用中间件，面试也是必问的点之一，一起来看看 MQ 的面试题。

**你们为什么使用 mq？具体的使用场景是什么？**
--------------------------

mq 的作用很简单，削峰填谷。以电商交易下单的场景来说，正向交易的过程可能涉及到创建订单、扣减库存、扣减活动预算、扣减积分等等。每个接口的耗时如果是 100ms，那么理论上整个下单的链路就需要耗费 400ms，这个时间显然是太长了。

![](https://pic3.zhimg.com/v2-9be1ef7a125254dcc46926a474a593b0_r.jpg?source=1940ef5c)

如果这些操作全部同步处理的话，首先调用链路太长影响接口性能，其次分布式事务的问题很难处理，这时候像扣减预算和积分这种对实时一致性要求没有那么高的请求，完全就可以通过 mq 异步的方式去处理了。同时，考虑到异步带来的不一致的问题，我们可以通过 job 去重试保证接口调用成功，而且一般公司都会有核对的平台，比如下单成功但是未扣减积分的这种问题可以通过核对作为兜底的处理方案。

![](https://pic1.zhimg.com/v2-f9080423841112d15a584666c205f231_r.jpg?source=1940ef5c)

使用 mq 之后我们的链路变简单了，同时异步发送消息我们的整个系统的抗压能力也上升了。

**那你们使用什么 mq？基于什么做的选型？**
------------------------

我们主要调研了几个主流的 mq，kafka、rabbitmq、rocketmq、activemq，选型我们主要基于以下几个点去考虑：

1.  由于我们系统的 qps 压力比较大，所以性能是首要考虑的要素。
2.  开发语言，由于我们的开发语言是 java，主要是为了方便二次开发。
3.  对于高并发的业务场景是必须的，所以需要支持分布式架构的设计。
4.  功能全面，由于不同的业务场景，可能会用到顺序消息、事务消息等。

基于以上几个考虑，我们最终选择了 RocketMQ。

![](https://pic2.zhimg.com/v2-f76688fef5f857a6e553e0814c496afe_r.jpg?source=1940ef5c)

**你上面提到异步发送，那消息可靠性怎么保证？**
-------------------------

消息丢失可能发生在生产者发送消息、MQ 本身丢失消息、消费者丢失消息 3 个方面。

**生产者丢失**
---------

生产者丢失消息的可能点在于程序发送失败抛异常了没有重试处理，或者发送的过程成功但是过程中网络闪断 MQ 没收到，消息就丢失了。

由于同步发送的一般不会出现这样使用方式，所以我们就不考虑同步发送的问题，我们基于异步发送的场景来说。

异步发送分为两个方式：**异步有回调和异步无回调**，无回调的方式，生产者发送完后不管结果可能就会造成消息丢失，而通过异步发送 + 回调通知 + 本地消息表的形式我们就可以做出一个解决方案。以下单的场景举例。

1.  下单后先保存本地数据和 MQ 消息表，这时候消息的状态是发送中，如果本地事务失败，那么下单失败，事务回滚。
2.  下单成功，直接返回客户端成功，异步发送 MQ 消息
3.  MQ 回调通知消息发送结果，对应更新数据库 MQ 发送状态
4.  JOB 轮询超过一定时间（时间根据业务配置）还未发送成功的消息去重试
5.  在监控平台配置或者 JOB 程序处理超过一定次数一直发送不成功的消息，告警，人工介入。

![](https://pic2.zhimg.com/v2-06c99b9df68e01755a5999f8bafd6757_r.jpg?source=1940ef5c)

一般而言，对于大部分场景来说异步回调的形式就可以了，只有那种需要完全保证不能丢失消息的场景我们做一套完整的解决方案。

**MQ 丢失**
---------

如果生产者保证消息发送到 MQ，而 MQ 收到消息后还在内存中，这时候宕机了又没来得及同步给从节点，就有可能导致消息丢失。

比如 RocketMQ：

RocketMQ 分为同步刷盘和异步刷盘两种方式，默认的是异步刷盘，就有可能导致消息还未刷到硬盘上就丢失了，可以通过设置为同步刷盘的方式来保证消息可靠性，这样即使 MQ 挂了，恢复的时候也可以从磁盘中去恢复消息。

比如 Kafka 也可以通过配置做到：

```
acks=all 只有参与复制的所有节点全部收到消息，才返回生产者成功。这样的话除非所有的节点都挂了，消息才会丢失。
replication.factor=N,设置大于1的数，这会要求每个partion至少有2个副本
min.insync.replicas=N，设置大于1的数，这会要求leader至少感知到一个follower还保持着连接
retries=N，设置一个非常大的值，让生产者发送失败一直重试
```

虽然我们可以通过配置的方式来达到 MQ 本身高可用的目的，但是都对性能有损耗，怎样配置需要根据业务做出权衡。

**消费者丢失**
---------

消费者丢失消息的场景：消费者刚收到消息，此时服务器宕机，MQ 认为消费者已经消费，不会重复发送消息，消息丢失。

RocketMQ 默认是需要消费者回复 ack 确认，而 kafka 需要手动开启配置关闭自动 offset。

消费方不返回 ack 确认，重发的机制根据 MQ 类型的不同发送时间间隔、次数都不尽相同，如果重试超过次数之后会进入死信队列，需要手工来处理了。（Kafka 没有这些）

![](https://pic2.zhimg.com/v2-340fc03b3dbac1acea04ce35ba67e279_r.jpg?source=1940ef5c)

**你说到消费者消费失败的问题，那么如果一直消费失败导致消息积压怎么处理？**
---------------------------------------

因为考虑到时消费者消费一直出错的问题，那么我们可以从以下几个角度来考虑：

1.  消费者出错，肯定是程序或者其他问题导致的，如果容易修复，先把问题修复，让 consumer 恢复正常消费
2.  如果时间来不及处理很麻烦，做转发处理，写一个临时的 consumer 消费方案，先把消息消费，然后再转发到一个新的 topic 和 MQ 资源，这个新的 topic 的机器资源单独申请，要能承载住当前积压的消息
3.  处理完积压数据后，修复 consumer，去消费新的 MQ 和现有的 MQ 数据，新 MQ 消费完成后恢复原状

![](https://pic1.zhimg.com/v2-504fab4697a15864a8ab984fbd10d8e4_r.jpg?source=1940ef5c)

**那如果消息积压达到磁盘上限，消息被删除了怎么办？**
----------------------------

这。。。他妈都删除了我有啥办法啊。。。冷静，再想想。。有了。

![](https://pic1.zhimg.com/v2-ca42892fc9c42e8a0fdf912e1e41a494_r.jpg?source=1940ef5c)

最初，我们发送的消息记录是落库保存了的，而转发发送的数据也保存了，那么我们就可以通过这部分数据来找到丢失的那部分数据，再单独跑个脚本重发就可以了。如果转发的程序没有落库，那就和消费方的记录去做对比，只是过程会更艰难一点。

**说了这么多，那你说说 RocketMQ 实现原理吧？**
------------------------------

RocketMQ 由 NameServer 注册中心集群、Producer 生产者集群、Consumer 消费者集群和若干 Broker（RocketMQ 进程）组成，它的架构原理是这样的：

1.  Broker 在启动的时候去向所有的 NameServer 注册，并保持长连接，每 30s 发送一次心跳
2.  Producer 在发送消息的时候从 NameServer 获取 Broker 服务器地址，根据负载均衡算法选择一台服务器来发送消息
3.  Conusmer 消费消息的时候同样从 NameServer 获取 Broker 地址，然后主动拉取消息来消费

![](https://pic2.zhimg.com/v2-2e24d9d9021901b9977bb1a94d610f54_r.jpg?source=1940ef5c)

**为什么 RocketMQ 不使用 Zookeeper 作为注册中心呢？**
---------------------------------------

我认为有以下几个点是不使用 zookeeper 的原因：

1.  根据 CAP 理论，同时最多只能满足两个点，而 zookeeper 满足的是 CP，也就是说 zookeeper 并不能保证服务的可用性，zookeeper 在进行选举的时候，整个选举的时间太长，期间整个集群都处于不可用的状态，而这对于一个注册中心来说肯定是不能接受的，作为服务发现来说就应该是为可用性而设计。
2.  基于性能的考虑，NameServer 本身的实现非常轻量，而且可以通过增加机器的方式水平扩展，增加集群的抗压能力，而 zookeeper 的写是不可扩展的，而 zookeeper 要解决这个问题只能通过划分领域，划分多个 zookeeper 集群来解决，首先操作起来太复杂，其次这样还是又违反了 CAP 中的 A 的设计，导致服务之间是不连通的。
3.  持久化的机制来带的问题，ZooKeeper 的 ZAB 协议对每一个写请求，会在每个 ZooKeeper 节点上保持写一个事务日志，同时再加上定期的将内存数据镜像（Snapshot）到磁盘来保证数据的一致性和持久性，而对于一个简单的服务发现的场景来说，这其实没有太大的必要，这个实现方案太重了。而且本身存储的数据应该是高度定制化的。
4.  消息发送应该弱依赖注册中心，而 RocketMQ 的设计理念也正是基于此，生产者在第一次发送消息的时候从 NameServer 获取到 Broker 地址后缓存到本地，如果 NameServer 整个集群不可用，短时间内对于生产者和消费者并不会产生太大影响。

**那 Broker 是怎么保存数据的呢？**
-----------------------

RocketMQ 主要的存储文件包括 commitlog 文件、consumequeue 文件、indexfile 文件。

Broker 在收到消息之后，会把消息保存到 commitlog 的文件当中，而同时在分布式的存储当中，每个 broker 都会保存一部分 topic 的数据，同时，每个 topic 对应的 messagequeue 下都会生成 consumequeue 文件用于保存 commitlog 的物理位置偏移量 offset，indexfile 中会保存 key 和 offset 的对应关系。

![](https://pic3.zhimg.com/v2-035524ddabba0b5eaefcd02a8136a967_r.jpg?source=1940ef5c)

CommitLog 文件保存于 ${Rocket_Home}/store/commitlog 目录中，从图中我们可以明显看出来文件名的偏移量，每个文件默认 1G，写满后自动生成一个新的文件。

![](https://pic3.zhimg.com/v2-6a9a48925df77d9d0e13af0bf09a7f04_r.jpg?source=1940ef5c)

由于同一个 topic 的消息并不是连续的存储在 commitlog 中，消费者如果直接从 commitlog 获取消息效率非常低，所以通过 consumequeue 保存 commitlog 中消息的偏移量的物理地址，这样消费者在消费的时候先从 consumequeue 中根据偏移量定位到具体的 commitlog 物理文件，然后根据一定的规则（offset 和文件大小取模）在 commitlog 中快速定位。

![](https://picx.zhimg.com/v2-ae625d5b151d59776e9d14bbb0739dd0_r.jpg?source=1940ef5c)

**Master 和 Slave 之间是怎么同步数据的呢？**
-------------------------------

而消息在 master 和 slave 之间的同步是根据 raft 协议来进行的：

1.  在 broker 收到消息后，会被标记为 uncommitted 状态
2.  然后会把消息发送给所有的 slave
3.  slave 在收到消息之后返回 ack 响应给 master
4.  master 在收到超过半数的 ack 之后，把消息标记为 committed
5.  发送 committed 消息给所有 slave，slave 也修改状态为 committed

**你知道 RocketMQ 为什么速度快吗？**
-------------------------

是因为使用了顺序存储、Page Cache 和异步刷盘。

1.  我们在写入 commitlog 的时候是顺序写入的，这样比随机写入的性能就会提高很多
2.  写入 commitlog 的时候并不是直接写入磁盘，而是先写入操作系统的 PageCache
3.  最后由操作系统异步将缓存中的数据刷到磁盘

**什么是事务、半事务消息？怎么实现的？**
----------------------

事务消息就是 MQ 提供的类似 XA 的分布式事务能力，通过事务消息可以达到分布式事务的最终一致性。

半事务消息就是 MQ 收到了生产者的消息，但是没有收到二次确认，不能投递的消息。

实现原理如下：

1.  生产者先发送一条半事务消息到 MQ
2.  MQ 收到消息后返回 ack 确认
3.  生产者开始执行本地事务
4.  如果事务执行成功发送 commit 到 MQ，失败发送 rollback
5.  如果 MQ 长时间未收到生产者的二次确认 commit 或者 rollback，MQ 对生产者发起消息回查
6.  生产者查询事务执行最终状态
7.  根据查询事务状态再次提交二次确认

最终，如果 MQ 收到二次确认 commit，就可以把消息投递给消费者，反之如果是 rollback，消息会保存下来并且在 3 天后被删除。

![](https://pic3.zhimg.com/v2-241a555aa77a0e9c87a8a9d7ab67b0a0_r.jpg?source=1940ef5c)

Spring
------

### **1. 说说 Spring 里用到了哪些设计模式?**

`单例模式`：Spring 中的 Bean 默认情况下都是单例的。无需多说。

`工厂模式`：工厂模式主要是通过 BeanFactory 和 ApplicationContext 来生产 Bean 对象。

`代理模式`：最常见的 AOP 的实现方式就是通过代理来实现，Spring 主要是使用 JDK 动态代理和 CGLIB 代理。

`模板方法模式`：主要是一些对数据库操作的类用到，比如 JdbcTemplate、JpaTemplate，因为查询数据库的建立连接、执行查询、关闭连接几个过程，非常适用于模板方法。

### **2. 谈谈你对 IOC 和 AOP 的理解？他们的实现原理是什么？**

IOC 叫做控制反转，指的是通过 Spring 来管理对象的创建、配置和生命周期，这样相当于把控制权交给了 Spring，不需要人工来管理对象之间复杂的依赖关系，这样做的好处就是解耦。在 Spring 里面，主要提供了 BeanFactory 和 ApplicationContext 两种 IOC 容器，通过他们来实现对 Bean 的管理。

AOP 叫做面向切面编程，他是一个编程范式，目的就是提高代码的模块性。Spring AOP 基于动态代理的方式实现，如果是实现了接口的话就会使用 JDK 动态代理，反之则使用 CGLIB 代理，Spring 中 AOP 的应用主要体现在 事务、日志、异常处理等方面，通过在代码的前后做一些增强处理，可以实现对业务逻辑的隔离，提高代码的模块化能力，同时也是解耦。Spring 主要提供了 Aspect 切面、JoinPoint 连接点、PointCut 切入点、Advice 增强等实现方式。

### **3. JDK 动态代理和 CGLIB 代理有什么区别？**

JDK 动态代理主要是针对类实现了某个接口，AOP 则会使用 JDK 动态代理。他基于反射的机制实现，生成一个实现同样接口的一个代理类，然后通过重写方法的方式，实现对代码的增强。

而如果某个类没有实现接口，AOP 则会使用 CGLIB 代理。他的底层原理是基于 asm 第三方框架，通过修改字节码生成成成一个子类，然后重写父类的方法，实现对代码的增强。

### **4. Spring AOP 和 AspectJ AOP 有什么区别？**

Spring AOP 基于动态代理实现，属于运行时增强。

AspectJ 则属于编译时增强，主要有 3 种方式：

1.  编译时织入：指的是增强的代码和源代码我们都有，直接使用 AspectJ 编译器编译就行了，编译之后生成一个新的类，他也会作为一个正常的 Java 类装载到 JVM。
2.  编译后织入：指的是代码已经被编译成 class 文件或者已经打成 jar 包，这时候要增强的话，就是编译后织入，比如你依赖了第三方的类库，又想对他增强的话，就可以通过这种方式。

![](https://pica.zhimg.com/v2-60d5dd4a92fd84ba63a1957da32e0c42_r.jpg?source=1940ef5c)

1.  加载时织入：指的是在 JVM 加载类的时候进行织入。

总结下来的话，就是 Spring AOP 只能在运行时织入，不需要单独编译，性能相比 AspectJ 编译织入的方式慢，而 AspectJ 只支持编译前后和类加载时织入，性能更好，功能更加强大。

### **5. FactoryBean 和 BeanFactory 有什么区别？**

BeanFactory 是 Bean 的工厂， ApplicationContext 的父类，IOC 容器的核心，负责生产和管理 Bean 对象。

FactoryBean 是 Bean，可以通过实现 FactoryBean 接口定制实例化 Bean 的逻辑，通过代理一个 Bean 对象，对方法前后做一些操作。

### **6.SpringBean 的生命周期说说？**

SpringBean 生命周期简单概括为 4 个阶段：

1.  实例化，创建一个 Bean 对象
2.  填充属性，为属性赋值
3.  初始化  
    

*   如果实现了`xxxAware`接口，通过不同类型的 Aware 接口拿到 Spring 容器的资源
*   如果实现了 BeanPostProcessor 接口，则会回调该接口的`postProcessBeforeInitialzation`和`postProcessAfterInitialization`方法
*   如果配置了`init-method`方法，则会执行`init-method`配置的方法

1.  销毁  
    

*   容器关闭后，如果 Bean 实现了`DisposableBean`接口，则会回调该接口的`destroy`方法
*   如果配置了`destroy-method`方法，则会执行`destroy-method`配置的方法

![](https://pic1.zhimg.com/v2-d49498dd4fa1bd9965d4e195dfb47189_r.jpg?source=1940ef5c)

### **7.Spring 是怎么解决循环依赖的？**

首先，Spring 解决循环依赖有两个前提条件：

1.  不全是构造器方式的循环依赖
2.  必须是单例

基于上面的问题，我们知道 Bean 的生命周期，本质上解决循环依赖的问题就是三级缓存，通过三级缓存提前拿到未初始化完全的对象。

第一级缓存：用来保存实例化、初始化都完成的对象

第二级缓存：用来保存实例化完成，但是未初始化完成的对象

第三级缓存：用来保存一个对象工厂，提供一个匿名内部类，用于创建二级缓存中的对象

![](https://pic1.zhimg.com/v2-77f7970df217096cfde3c9a23e994c6c_r.jpg?source=1940ef5c)

假设一个简单的循环依赖场景，A、B 互相依赖。

![](https://pica.zhimg.com/v2-dafa18c3216ad4441b8a7db122e9eac5_r.jpg?source=1940ef5c)

A 对象的创建过程：

1.  创建对象 A，实例化的时候把 A 对象工厂放入三级缓存

![](https://pic1.zhimg.com/v2-33086d67af7602d481e43ddcf277aaf1_r.jpg?source=1940ef5c)

1.  A 注入属性时，发现依赖 B，转而去实例化 B
2.  同样创建对象 B，注入属性时发现依赖 A，一次从一级到三级缓存查询 A，从三级缓存通过对象工厂拿到 A，把 A 放入二级缓存，同时删除三级缓存中的 A，此时，B 已经实例化并且初始化完成，把 B 放入一级缓存。

![](https://pic1.zhimg.com/v2-333d37489fd84ae23ccdfa16c68d4fb2_r.jpg?source=1940ef5c)

1.  接着继续创建 A，顺利从一级缓存拿到实例化且初始化完成的 B 对象，A 对象创建也完成，删除二级缓存中的 A，同时把 A 放入一级缓存
2.  最后，一级缓存中保存着实例化、初始化都完成的 A、B 对象

![](https://pic3.zhimg.com/v2-7e197a5087b3eacd8bf66bee118b5cdf_r.jpg?source=1940ef5c)

因此，由于把实例化和初始化的流程分开了，所以如果都是用构造器的话，就没法分离这个操作，所以都是构造器的话就无法解决循环依赖的问题了。

### **8. 为什么要三级缓存？二级不行吗？**

不可以，主要是为了生成代理对象。

因为三级缓存中放的是生成具体对象的匿名内部类，他可以生成代理对象，也可以是普通的实例对象。

使用三级缓存主要是为了保证不管什么时候使用的都是一个对象。

假设只有二级缓存的情况，往二级缓存中放的显示一个普通的 Bean 对象，`BeanPostProcessor`去生成代理对象之后，覆盖掉二级缓存中的普通 Bean 对象，那么多线程环境下可能取到的对象就不一致了。

![](https://pic2.zhimg.com/v2-e4e9050787017c7272dc313f88af9382_r.jpg?source=1940ef5c)

### **9.Spring 事务传播机制有哪些？**

1.  **PROPAGATION_REQUIRED**：如果当前没有事务，就创建一个新事务，如果当前存在事务，就加入该事务，这也是通常我们的默认选择。
2.  **PROPAGATION_REQUIRES_NEW**：创建新事务，无论当前存不存在事务，都创建新事务。
3.  PROPAGATION_NESTED：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则按 REQUIRED 属性执行。
4.  PROPAGATION_NOT_SUPPORTED：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。
5.  PROPAGATION_NEVER：以非事务方式执行，如果当前存在事务，则抛出异常。
6.  PROPAGATION_MANDATORY：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就抛出异常。
7.  PROPAGATION_SUPPORTS：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就以非事务执行。‘

### **10. 最后，说说 Spring Boot 启动流程吧？**

这个流程，网上一搜基本都是这张图了，我也不想再画一遍了。那其实主要的流程就几个步骤：

1.  准备环境，根据不同的环境创建不同的 Environment
2.  准备、加载上下文，为不同的环境选择不同的 Spring Context，然后加载资源，配置 Bean
3.  初始化，这个阶段刷新 Spring Context，启动应用
4.  最后结束流程

![](https://pic1.zhimg.com/v2-fc1438165d54ad9b5846226947ba2764_r.jpg?source=1940ef5c)

Zookeeper
---------

### **谈谈你对 Zookeeper 的理解？**

Zookeeper 是一个开源的分布式协调服务，由雅虎公司创建，由于最初雅虎公司的内部研究小组的项目大多以动物的名字命名，所以后来就以 Zookeeper(动物管理员) 来命名了，而就是由 Zookeeper 来负责这些分布式组件环境的协调工作。

他的目标是可以提供高性能、高可用和顺序访问控制的能力，同时也是为了解决分布式环境下数据一致性的问题。

**集群**

首先，Zookeeper 集群中有几个关键的概念，Leader、Follower 和 Observer，Zookeeper 中通常只有 Leader 节点可以写入，Follower 和 Observer 都只是负责读，但是 Follower 会参与节点的选举和**过半写成功**，Observer 则不会，他只是单纯的提供读取数据的功能。

通常这样设置的话，是为了避免太多的从节点参与过半写的过程，导致影响性能，这样 Zookeeper 只要使用一个几台机器的小集群就可以实现高性能了，如果要横向扩展的话，只需要增加 Observer 节点即可。

Zookeeper 建议集群节点个数为奇数，只要超过一半的机器能够正常提供服务，那么整个集群都是可用的状态。

![](https://pic1.zhimg.com/v2-1e890231a5caeb688928157eac396877_r.jpg?source=1940ef5c)

**数据节点 Znode**

Zookeeper 中数据存储于内存之中，这个数据节点就叫做 Znode，他是一个树形结构，比如 / a/b/c 类似。

而 Znode 又分为持久节点、临时节点、顺序节点三大类。

持久节点是指只要被创建，除非主动移除，否则都应该一直保存在 Zookeeper 中。

临时节点不同的是，他的生命周期和客户端 Session 会话一样，会话失效，那么临时节点就会被移除。

还有就是临时顺序节点和持久顺序节点，除了基本的特性之外，子节点的名称还具有有序性。

**会话 Session**

会话自然就是指 Zookeeper 客户端和服务端之间的通信，他们使用 TCP 长连接的方式保持通信，通常，肯定会有心跳检测的机制，同时他可以接受来自服务器的 Watch 事件通知。

**事件监听器 Wather**

用户可以在指定的节点上注册 Wather，这样在事件触发的时候，客户端就会收到来自服务端的通知。

**权限控制 ACL**

Zookeeper 使用 ACL 来进行权限的控制，包含以下 5 种：

1.  CREATE，创建子节点权限
2.  DELETE，删除子节点权限
3.  READ，获取节点数据和子节点列表权限
4.  WRITE，更新节点权限
5.  ADMIN，设置节点 ACL 权限

所以，Zookeeper 通过集群的方式来做到高可用，通过内存数据节点 Znode 来达到高性能，但是存储的数据量不能太大，通常适用于读多写少的场景。

### **Zookeeper 有哪些应用场景？**

1.  命名服务 Name Service，依赖 Zookeeper 可以生成全局唯一的节点 ID，来对分布式系统中的资源进行管理。
2.  分布式协调，这是 Zookeeper 的核心使用了。利用 Wather 的监听机制，一个系统的某个节点状态发生改变，另外系统可以得到通知。
3.  集群管理，分布式集群中状态的监控和管理，使用 Zookeeper 来存储。
4.  Master 选举，利用 Zookeeper 节点的全局唯一性，同时只有一个客户端能够创建成功的特点，可以作为 Master 选举使用，创建成功的则作为 Master。
5.  分布式锁，利用 Zookeeper 创建临时顺序节点的特性。

### **说说 Wather 监听机制和它的原理？**

Zookeeper 可以提供分布式数据的发布 / 订阅功能，依赖的就是 Wather 监听机制。

客户端可以向服务端注册 Wather 监听，服务端的指定事件触发之后，就会向客户端发送一个事件通知。

他有几个特性：

1.  一次性：一旦一个 Wather 触发之后，Zookeeper 就会将它从存储中移除
2.  客户端串行：客户端的 Wather 回调处理是串行同步的过程，不要因为一个 Wather 的逻辑阻塞整个客户端
3.  轻量：Wather 通知的单位是 WathedEvent，只包含通知状态、事件类型和节点路径，不包含具体的事件内容，具体的时间内容需要客户端主动去重新获取数据

主要流程如下：

1.  客户端向服务端注册 Wather 监听
2.  保存 Wather 对象到客户端本地的 WatherManager 中
3.  服务端 Wather 事件触发后，客户端收到服务端通知，从 WatherManager 中取出对应 Wather 对象执行回调逻辑

![](https://pic2.zhimg.com/v2-95af46999d513941fb635faf4f8c8755_r.jpg?source=1940ef5c)

### **Zookeeper 是如何保证数据一致性的？**

Zookeeper 通过 ZAB 原子广播协议来实现数据的最终顺序一致性，他是一个类似 2PC 两阶段提交的过程。

由于 Zookeeper 只有 Leader 节点可以写入数据，如果是其他节点收到写入数据的请求，则会将之转发给 Leader 节点。

主要流程如下：

1.  Leader 收到请求之后，将它转换为一个 proposal 提议，并且为每个提议分配一个全局唯一递增的事务 ID：zxid，然后把提议放入到一个 FIFO 的队列中，按照 FIFO 的策略发送给所有的 Follower
2.  Follower 收到提议之后，以事务日志的形式写入到本地磁盘中，写入成功后返回 ACK 给 Leader
3.  Leader 在收到超过半数的 Follower 的 ACK 之后，即可认为数据写入成功，就会发送 commit 命令给 Follower 告诉他们可以提交 proposal 了

![](https://pic4.zhimg.com/v2-ae9a823d6576cf002aa22a3cc366be43_r.jpg?source=1940ef5c)

ZAB 包含两种基本模式，崩溃恢复和消息广播。

整个集群服务在启动、网络中断或者重启等异常情况的时候，首先会进入到崩溃恢复状态，此时会通过选举产生 Leader 节点，当集群过半的节点都和 Leader 状态同步之后，ZAB 就会退出恢复模式。之后，就会进入消息广播的模式。

### **那么，Zookeeper 如何进行 Leader 选举的？**

Leader 的选举可以分为两个方面，同时选举主要包含事务 zxid 和 myid，节点主要包含 LEADING\FOLLOWING\LOOKING3 个状态。

1.  服务启动期间的选举
2.  服务运行期间的选举

**服务启动期间的选举**

1.  首先，每个节点都会对自己进行投票，然后把投票信息广播给集群中的其他节点
2.  节点接收到其他节点的投票信息，然后和自己的投票进行比较，首先 zxid 较大的优先，如果 zxid 相同那么则会去选择 myid 更大者，此时大家都是 LOOKING 的状态
3.  投票完成之后，开始统计投票信息，如果集群中过半的机器都选择了某个节点机器作为 leader，那么选举结束
4.  最后，更新各个节点的状态，leader 改为 LEADING 状态，follower 改为 FOLLOWING 状态

**服务运行期间的选举**

如果开始选举出来的 leader 节点宕机了，那么运行期间就会重新进行 leader 的选举。

1.  leader 宕机之后，非 observer 节点都会把自己的状态修改为 LOOKING 状态，然后重新进入选举流程
2.  生成投票信息 (myid,zxid)，同样，第一轮的投票大家都会把票投给自己，然后把投票信息广播出去
3.  接下来的流程和上面的选举是一样的，都会优先以 zxid，然后选择 myid，最后统计投票信息，修改节点状态，选举结束

### **那选举之后又是怎样进行数据同步的？**

那实际上 Zookeeper 在选举之后，Follower 和 Observer（统称为 Learner）就会去向 Leader 注册，然后就会开始数据同步的过程。

数据同步包含 3 个主要值和 4 种形式。

PeerLastZxid：Learner 服务器最后处理的 ZXID

minCommittedLog：Leader 提议缓存队列中最小 ZXID

maxCommittedLog：Leader 提议缓存队列中最大 ZXID

**直接差异化同步 DIFF 同步**

如果 PeerLastZxid 在 minCommittedLog 和 maxCommittedLog 之间，那么则说明 Learner 服务器还没有完全同步最新的数据。

1.  首先 Leader 向 Learner 发送 DIFF 指令，代表开始差异化同步，然后把差异数据（从 PeerLastZxid 到 maxCommittedLog 之间的数据）提议 proposal 发送给 Learner
2.  发送完成之后发送一个 NEWLEADER 命令给 Learner，同时 Learner 返回 ACK 表示已经完成了同步
3.  接着等待集群中过半的 Learner 响应了 ACK 之后，就发送一个 UPTODATE 命令，Learner 返回 ACK，同步流程结束

![](https://pica.zhimg.com/v2-db95cfec85a1f898298643acb9c5a344_r.jpg?source=1940ef5c)

**先回滚再差异化同步 TRUNC+DIFF 同步**

这个设置针对的是一个异常的场景。

如果 Leader 刚生成一个 proposal，还没有来得及发送出去，此时 Leader 宕机，重新选举之后作为 Follower，但是新的 Leader 没有这个 proposal 数据。

举个栗子：

假设现在的 Leader 是 A，minCommittedLog=1，maxCommittedLog=3，刚好生成的一个 proposal 的 ZXID=4，然后挂了。

重新选举出来的 Leader 是 B，B 之后又处理了 2 个提议，然后 minCommittedLog=1，maxCommittedLog=5。

这时候 A 的 PeerLastZxid=4，在 (1,5) 之间。

那么这一条只存在于 A 的提议怎么处理？

A 要进行事务回滚，相当于抛弃这条数据，并且回滚到最接近于 PeerLastZxid 的事务，对于 A 来说，也就是 PeerLastZxid=3。

流程和 DIFF 一致，只是会先发送一个 TRUNC 命令，然后再执行差异化 DIFF 同步。

**仅回滚同步 TRUNC 同步**

针对 PeerLastZxid 大于 maxCommittedLog 的场景，流程和上述一致，事务将会被回滚到 maxCommittedLog 的记录。

这个其实就更简单了，也就是你可以认为 TRUNC+DIFF 中的例子，新的 Leader B 没有处理提议，所以 B 中 minCommittedLog=1，maxCommittedLog=3。

所以 A 的 PeerLastZxid=4 就会大于 maxCommittedLog 了，也就是 A 只需要回滚就行了，不需要执行差异化同步 DIFF 了。

**全量同步 SNAP 同步**

适用于两个场景：

1.  PeerLastZxid 小于 minCommittedLog
2.  Leader 服务器上没有提议缓存队列，并且 PeerLastZxid 不等于 Leader 的最大 ZXID

这两种场景下，Leader 将会发送 SNAP 命令，把全量的数据都发送给 Learner 进行同步。

### **有可能会出现数据不一致的问题吗？**

还是会存在的，我们可以分成 3 个场景来描述这个问题。

**查询不一致**

因为 Zookeeper 是过半成功即代表成功，假设我们有 5 个节点，如果 123 节点写入成功，如果这时候请求访问到 4 或者 5 节点，那么有可能读取不到数据，因为可能数据还没有同步到 4、5 节点中，也可以认为这算是数据不一致的问题。

解决方案可以在读取前使用 sync 命令。

**leader 未发送 proposal 宕机**

这也就是数据同步说过的问题。

leader 刚生成一个 proposal，还没有来得及发送出去，此时 leader 宕机，重新选举之后作为 follower，但是新的 leader 没有这个 proposal。

这种场景下的日志将会被丢弃。

**leader 发送 proposal 成功，发送 commit 前宕机**

如果发送 proposal 成功了，但是在将要发送 commit 命令前宕机了，如果重新进行选举，还是会选择 zxid 最大的节点作为 leader，因此，这个日志并不会被丢弃，会在选举出 leader 之后重新同步到其他节点当中。

### **如果作为注册中心，Zookeeper 和 Eureka、Consul、Nacos 有什么区别？**

<table data-draft-node="block" data-draft-type="table" data-size="normal"><tbody><tr><th></th><th>Nacos</th><th>Eureka</th><th>Consul</th><th>Zookeeper</th></tr></tbody></table>

### **最后，你对于 CAP 理论怎么理解？**

CAP 是一个分布式系统设计的定理，他包含 3 个部分，并且最多只能同时满足其中两个。

1.  Consistency 一致性，因为在一个分布式系统中，数据肯定需要在不同的节点之间进行同步，就比如 Zookeeper，所以一致性就是指的是数据在不同的节点之间怎样保证一致性，对于纯理论的 C 而言，默认的规则是忽略掉延迟的，因为如果考虑延迟的话，因为数据同步的过程无论如何都会有延迟的，延迟的过程必然会带来数据的不一致。
2.  Availability 可用性，这个指的是对于每一个请求，节点总是可以在合理的时间返回合理的响应，比如 Zookeeper 在进行数据同步时，无法对外提供读写服务，不满足可用性要求。这里常有的一个例子是说 Zookeeper 选举期间无法提供服务不满足 A，这个说法并不准确，因为 CAP 关注的是数据的读写，选举可以认为不在考虑范围之内。所以，可以认为对于数据的读写，无论响应超时还是返回异常都可以认为是不满足 A。
3.  Partition-tolerance 分区容错性，因为在一个分布式系统当中，很有可能由于部分节点的网络问题导致整个集群之间的网络不连通，所以就产生了网络分区，整个集群的环境被分隔成不同的的子网，所以，一般说网络不可能 100% 的不产生问题，所以 P 一定会存在。

为什么只能同时满足 CAP 中的两个呢？

以 A\B 两个节点同步数据举例，由于 P 的存在，那么可能 AB 同步数据出现问题。

如果选择 AP，由于 A 的数据未能正确同步到 B，所以 AB 数据不一致，无法满足 C。

如果选择 CP，那么 B 就不能提供服务，就无法满足 A。

Dubbo
-----

这是面试专题系列第四篇，Dubbo 系列。Dubbo 本身并不复杂，而且官方文档写的非常清楚详细，面试中 dubbo 的问题一般不会很多，从分层到工作原理、负载均衡策略、容错机制、SPI 机制基本就差不多了，最大的一道大题一般就是怎么设计一个 RPC 框架了，但是如果你工作原理分层都搞明白了这个问题其实也就相当于回答了不是吗。

**说说 Dubbo 的分层？**
-----------------

从大的范围来说，dubbo 分为三层，business 业务逻辑层由我们自己来提供接口和实现还有一些配置信息，RPC 层就是真正的 RPC 调用的核心层，封装整个 RPC 的调用过程、负载均衡、集群容错、代理，remoting 则是对网络传输协议和数据转换的封装。

划分到更细的层面，就是图中的 10 层模式，整个分层依赖由上至下，除开 business 业务逻辑之外，其他的几层都是 SPI 机制。

![](https://pic2.zhimg.com/v2-ead309d1394216b97770a928941ce661_r.jpg?source=1940ef5c)

**能说下 Dubbo 的工作原理吗？**
---------------------

1.  服务启动的时候，provider 和 consumer 根据配置信息，连接到注册中心 register，分别向注册中心注册和订阅服务
2.  register 根据服务订阅关系，返回 provider 信息到 consumer，同时 consumer 会把 provider 信息缓存到本地。如果信息有变更，consumer 会收到来自 register 的推送
3.  consumer 生成代理对象，同时根据负载均衡策略，选择一台 provider，同时定时向 monitor 记录接口的调用次数和时间信息
4.  拿到代理对象之后，consumer 通过代理对象发起接口调用
5.  provider 收到请求后对数据进行反序列化，然后通过代理调用具体的接口实现

![](https://pic3.zhimg.com/v2-477315efbff33f8ed68639f4d6bb6b82_r.jpg?source=1940ef5c)

**为什么要通过代理对象通信？**
-----------------

主要是为了实现接口的透明代理，封装调用细节，让用户可以像调用本地方法一样调用远程方法，同时还可以通过代理实现一些其他的策略，比如：

1、调用的负载均衡策略

2、调用失败、超时、降级和容错机制

3、做一些过滤操作，比如加入缓存、mock 数据

4、接口调用数据统计

**说说服务暴露的流程？**
--------------

1.  在容器启动的时候，通过 ServiceConfig 解析标签，创建 dubbo 标签解析器来解析 dubbo 的标签，容器创建完成之后，触发 ContextRefreshEvent 事件回调开始暴露服务
2.  通过 ProxyFactory 获取到 invoker，invoker 包含了需要执行的方法的对象信息和具体的 URL 地址
3.  再通过 DubboProtocol 的实现把包装后的 invoker 转换成 exporter，然后启动服务器 server，监听端口
4.  最后 RegistryProtocol 保存 URL 地址和 invoker 的映射关系，同时注册到服务中心

![](https://pica.zhimg.com/v2-f705392ebbf856974613bc85104d08f2_r.jpg?source=1940ef5c)

**说说服务引用的流程？**
--------------

服务暴露之后，客户端就要引用服务，然后才是调用的过程。

1.  首先客户端根据配置文件信息从注册中心订阅服务
2.  之后 DubboProtocol 根据订阅的得到 provider 地址和接口信息连接到服务端 server，开启客户端 client，然后创建 invoker
3.  invoker 创建完成之后，通过 invoker 为服务接口生成代理对象，这个代理对象用于远程调用 provider，服务的引用就完成了  
    

![](https://pic2.zhimg.com/v2-fbd0b902c11f8569bd65ebfbfba82b87_r.jpg?source=1940ef5c)

**有哪些负载均衡策略？**
--------------

1.  加权随机：假设我们有一组服务器 servers = [A, B, C]，他们对应的权重为 weights = [5, 3, 2]，权重总和为 10。现在把这些权重值平铺在一维坐标值上，[0, 5) 区间属于服务器 A，[5, 8) 区间属于服务器 B，[8, 10) 区间属于服务器 C。接下来通过随机数生成器生成一个范围在 [0, 10) 之间的随机数，然后计算这个随机数会落到哪个区间上就可以了。
2.  最小活跃数：每个服务提供者对应一个活跃数 active，初始情况下，所有服务提供者活跃数均为 0。每收到一个请求，活跃数加 1，完成请求后则将活跃数减 1。在服务运行一段时间后，性能好的服务提供者处理请求的速度更快，因此活跃数下降的也越快，此时这样的服务提供者能够优先获取到新的服务请求。
3.  一致性 hash：通过 hash 算法，把 provider 的 invoke 和随机节点生成 hash，并将这个 hash 投射到 [0, 2^32 - 1] 的圆环上，查询的时候根据 key 进行 md5 然后进行 hash，得到第一个节点的值大于等于当前 hash 的 invoker。

![](https://pic2.zhimg.com/v2-37cb4102be06c50b10ca9f218532830f_r.jpg?source=1940ef5c)

1.  加权轮询：比如服务器 A、B、C 权重比为 5:2:1，那么在 8 次请求中，服务器 A 将收到其中的 5 次请求，服务器 B 会收到其中的 2 次请求，服务器 C 则收到其中的 1 次请求。

**集群容错方式有哪些？**
--------------

1.  Failover Cluster 失败自动切换：dubbo 的默认容错方案，当调用失败时自动切换到其他可用的节点，具体的重试次数和间隔时间可用通过引用服务的时候配置，默认重试次数为 1 也就是只调用一次。
2.  Failback Cluster 失败自动恢复：在调用失败，记录日志和调用信息，然后返回空结果给 consumer，并且通过定时任务每隔 5 秒对失败的调用进行重试
3.  Failfast Cluster 快速失败：只会调用一次，失败后立刻抛出异常
4.  Failsafe Cluster 失败安全：调用出现异常，记录日志不抛出，返回空结果
5.  Forking Cluster 并行调用多个服务提供者：通过线程池创建多个线程，并发调用多个 provider，结果保存到阻塞队列，只要有一个 provider 成功返回了结果，就会立刻返回结果
6.  Broadcast Cluster 广播模式：逐个调用每个 provider，如果其中一台报错，在循环调用结束后，抛出异常。

**了解 Dubbo SPI 机制吗？**
---------------------

SPI 全称为 Service Provider Interface，是一种服务发现机制，本质是将接口实现类的全限定名配置在文件中，并由服务加载器读取配置文件，加载实现类，这样可以在运行时，动态为接口替换实现类。

Dubbo 也正是通过 SPI 机制实现了众多的扩展功能，而且 dubbo 没有使用 java 原生的 SPI 机制，而是对齐进行了增强和改进。

SPI 在 dubbo 应用很多，包括协议扩展、集群扩展、路由扩展、序列化扩展等等。

使用方式可以在 META-INF/dubbo 目录下配置：

```
key=com.xxx.value
```

然后通过 dubbo 的 ExtensionLoader 按照指定的 key 加载对应的实现类，这样做的好处就是可以按需加载，性能上得到优化。

**如果让你实现一个 RPC 框架怎么设计？**
------------------------

1.  首先需要一个服务注册中心，这样 consumer 和 provider 才能去注册和订阅服务
2.  需要负载均衡的机制来决定 consumer 如何调用客户端，这其中还当然要包含容错和重试的机制
3.  需要通信协议和工具框架，比如通过 http 或者 rmi 的协议通信，然后再根据协议选择使用什么框架和工具来进行通信，当然，数据的传输序列化也要考虑
4.  除了基本的要素之外，像一些监控、配置管理页面、日志是额外的优化考虑因素。

那么，本质上，只要熟悉一两个 RPC 框架，就很容易想明白我们自己要怎么实现一个 RPC 框架。

网络
--

### **谈一谈你对 TCP/IP 四层模型，OSI 七层模型的理解？**

为了增强通用性和兼容性，计算机网络都被设计成层次机构，每一层都遵守一定的规则。

因此有了 OSI 这样一个抽象的网络通信参考模型，按照这个标准使计算机网络系统可以互相连接。

**物理层**：通过网线、光缆等这种物理方式将电脑连接起来。传递的数据是**比特流**，0101010100。

**数据链路层**： 首先，把比特流封装成数据**帧**的格式，对 0、1 进行分组。电脑连接起来之后，数据都经过网卡来传输，而网卡上定义了全世界唯一的 MAC 地址。然后再通过广播的形式向局域网内所有电脑发送数据，再根据数据中 MAC 地址和自身对比判断是否是发给自己的。

**网络层**：广播的形式太低效，为了区分哪些 MAC 地址属于同一个子网，网络层定义了 IP 和子网掩码，通过对 IP 和子网掩码进行与运算就知道是否是同一个子网，再通过路由器和交换机进行传输。IP 协议属于网络层的协议。

**传输层**：有了网络层的 MAC+IP 地址之后，为了确定数据包是从哪个进程发送过来的，就需要端口号，通过端口来建立通信，比如 TCP 和 UDP 属于这一层的协议。

**会话层**：负责建立和断开连接

**表示层**：为了使得数据能够被其他的计算机理解，再次将数据转换成另外一种格式，比如文字、视频、图片等。

**应用层**：最高层，面对用户，提供计算机网络与最终呈现给用户的界面

![](https://pic1.zhimg.com/v2-d4fd93998d42b347ab6861c745b4c5d9_r.jpg?source=1940ef5c)

TCP/IP 则是四层的结构，相当于是对 OSI 模型的简化。

1.  数据链路层，也有称作网络访问层、网络接口层。他包含了 OSI 模型的物理层和数据链路层，把电脑连接起来。
2.  网络层，也叫做 IP 层，处理 IP 数据包的传输、路由，建立主机间的通信。
3.  传输层，就是为两台主机设备提供端到端的通信。
4.  应用层，包含 OSI 的会话层、表示层和应用层，提供了一些常用的协议规范，比如 FTP、SMPT、HTTP 等。

总结下来，就是物理层通过物理手段把电脑连接起来，数据链路层则对比特流的数据进行分组，网络层来建立主机到主机的通信，传输层建立端口到端口的通信，应用层最终负责建立连接，数据格式转换，最终呈现给用户。

### **说说 TCP 3 次握手的过程？**

建立连接前 server 端需要监听端口，所以初始状态是 LISTEN。

1.  client 端建立连接，发送一个 SYN 同步包，发送之后状态变成 SYN_SENT
2.  server 端收到 SYN 之后，同意建立连接，返回一个 ACK 响应，同时也会给 client 发送一个 SYN 包，发送完成之后状态变为 SYN_RCVD
3.  client 端收到 server 的 ACK 之后，状态变为 ESTABLISHED，返回 ACK 给 server 端。server 收到之后状态也变为 ESTABLISHED，连接建立完成。

![](https://pic2.zhimg.com/v2-ce0cee31b3f394ea866466a6fc39077b_r.jpg?source=1940ef5c)

### **为什么要 3 次？2 次，4 次不行吗？**

因为 TCP 是双工传输模式，不区分客户端和服务端，连接的建立是双向的过程。

如果只有两次，无法做到双向连接的建立，从建立连接 server 回复的 SYN 和 ACK 合并成一次可以看出来，他也不需要 4 次。

挥手为什么要四次？因为挥手的 ACK 和 FIN 不能同时发送，因为数据发送的截止时间不同。

### **那么四次挥手的过程呢？**

1.  client 端向 server 发送 FIN 包，进入 FIN_WAIT_1 状态，这代表 client 端已经没有数据要发送了
2.  server 端收到之后，返回一个 ACK，进入 CLOSE_WAIT 等待关闭的状态，因为 server 端可能还有没有发送完成的数据
3.  等到 server 端数据都发送完毕之后，server 端就向 client 发送 FIN，进入 LAST_ACK 状态
4.  client 收到 ACK 之后，进入 TIME_WAIT 的状态，同时回复 ACK，server 收到之后直接进入 CLOSED 状态，连接关闭。但是 client 要等待 2MSL(报文最大生存时间) 的时间，才会进入 CLOSED 状态。

![](https://pic2.zhimg.com/v2-b6311cb85e26238eabaa4d6a44ec98d0_r.jpg?source=1940ef5c)

### **为什么要等待 2MSL 的时间才关闭？**

1.  为了保证连接的可靠关闭。如果 server 没有收到最后一个 ACK，那么就会重发 FIN。
2.  为了避免端口重用带来的数据混淆。如果 client 直接进入 CLOSED 状态，又用相同端口号向 server 建立一个连接，上一次连接的部分数据在网络中延迟到达 server，数据就可能发生混淆了。

### **TCP 怎么保证传输过程的可靠性？**

**校验和**：发送方在发送数据之前计算校验和，接收方收到数据后同样计算，如果不一致，那么传输有误。

**确认应答，序列号**：TCP 进行传输时数据都进行了编号，每次接收方返回 ACK 都有确认序列号。

**超时重传**：如果发送方发送数据一段时间后没有收到 ACK，那么就重发数据。

**连接管理**：三次握手和四次挥手的过程。

**流量控制**：TCP 协议报头包含 16 位的窗口大小，接收方会在返回 ACK 时同时把自己的即时窗口填入，发送方就根据报文中窗口的大小控制发送速度。

**拥塞控制**：刚开始发送数据的时候，拥塞窗口是 1，以后每次收到 ACK，则拥塞窗口 + 1，然后将拥塞窗口和收到的窗口取较小值作为实际发送的窗口，如果发生超时重传，拥塞窗口重置为 1。这样做的目的就是为了保证传输过程的高效性和可靠性。

### **说下浏览器请求一个网址的过程？**

1.  首先通过 DNS 服务器把域名解析成 IP 地址，通过 IP 和子网掩码判断是否属于同一个子网
2.  构造应用层请求 http 报文，传输层添加 TCP/UDP 头部，网络层添加 IP 头部，数据链路层添加以太网协议头部
3.  数据经过路由器、交换机转发，最终达到目标服务器，目标服务器同样解析数据，最终拿到 http 报文，按照对应的程序的逻辑响应回去。

![](https://pic3.zhimg.com/v2-1dc878923531d4cea5a4047fa2b9f5c9_r.jpg?source=1940ef5c)

### **知道 HTTPS 的工作原理吗？**

1.  用户通过浏览器请求 https 网站，服务器收到请求，选择浏览器支持的加密和 hash 算法，同时返回数字证书给浏览器，包含颁发机构、网址、公钥、证书有效期等信息。
2.  浏览器对证书的内容进行校验，如果有问题，则会有一个提示警告。否则，就生成一个随机数 X，同时使用证书中的公钥进行加密，并且发送给服务器。
3.  服务器收到之后，使用私钥解密，得到随机数 X，然后使用 X 对网页内容进行加密，返回给浏览器
4.  浏览器则使用 X 和之前约定的加密算法进行解密，得到最终的网页内容

![](https://pic2.zhimg.com/v2-45930608e106d5266b72f90547ad9ca2_r.jpg?source=1940ef5c)

### **负载均衡有哪些实现方式？**

**DNS**：这是最简单的负载均衡的方式，一般用于实现地理级别的负载均衡，不同地域的用户通过 DNS 的解析可以返回不同的 IP 地址，这种方式的负载均衡简单，但是扩展性太差，控制权在域名服务商。

**Http 重定向**：通过修改 Http 响应头的 Location 达到负载均衡的目的，Http 的 302 重定向。这种方式对性能有影响，而且增加请求耗时。

**反向代理**：作用于应用层的模式，也被称作为**七层负载均衡**，比如常见的 Nginx，性能一般可以达到万级。这种方式部署简单，成本低，而且容易扩展。

**IP**：作用于网络层的和传输层的模式，也被称作**四层负载均衡**，通过对数据包的 IP 地址和端口进行修改来达到负载均衡的效果。常见的有 LVS（Linux Virtual Server），通常性能可以支持 10 万级并发。

按照类型来划分的话，还可以分成 DNS 负载均衡、硬件负载均衡、软件负载均衡。

其中硬件负载均衡价格昂贵，性能最好，能达到百万级，软件负载均衡包括 Nginx、LVS 这种。

### **说说 BIO/NIO/AIO 的区别？**

**BIO**：同步阻塞 IO，每一个客户端连接，服务端都会对应一个处理线程，对于没有分配到处理线程的连接就会被阻塞或者拒绝。相当于是**一个连接一个线程**。

![](https://pica.zhimg.com/v2-a6bde877860658ddcb5c156035ce656b_r.jpg?source=1940ef5c)

**NIO**：同步非阻塞 IO，基于 Reactor 模型，客户端和 channel 进行通信，channel 可以进行读写操作，通过多路复用器 selector 来轮询注册在其上的 channel，而后再进行 IO 操作。这样的话，在进行 IO 操作的时候再用一个线程去处理就可以了，也就是**一个请求一个线程**。

![](https://pic3.zhimg.com/v2-5be1eca73fe9c7880533779c571e8757_r.jpg?source=1940ef5c)

**AIO**：异步非阻塞 IO，相比 NIO 更进一步，完全由操作系统来完成请求的处理，然后通知服务端开启线程去进行处理，因此是**一个有效请求一个线程**。

### **那么你怎么理解同步和阻塞？**

首先，可以认为一个 IO 操作包含两个部分：

1.  发起 IO 请求
2.  实际的 IO 读写操作

同步和异步在于第二个，实际的 IO 读写操作，如果操作系统帮你完成了再通知你，那就是异步，否则都叫做同步。

阻塞和非阻塞在于第一个，发起 IO 请求，对于 NIO 来说通过 channel 发起 IO 操作请求后，其实就返回了，所以是非阻塞。

### **谈一下你对 Reactor 模型的理解？**

Reactor 模型包含两个组件：

1.  Reactor：负责查询、响应 IO 事件，当检测到 IO 事件时，分发给 Handlers 处理。
2.  Handler：与 IO 事件绑定，负责 IO 事件的处理。

它包含几种实现方式：

**单线程 Reactor**

这个模式 reactor 和 handler 在一个线程中，如果某个 handler 阻塞的话，会导致其他所有的 handler 无法执行，而且无法充分利用多核的性能。

![](https://pic1.zhimg.com/v2-7c3ff3b8abf6432b26c72188076f0d3b_r.jpg?source=1940ef5c)

**单 Reactor 多线程**

由于 decode、compute、encode 的操作并非 IO 的操作，多线程 Reactor 的思路就是充分发挥多核的特性，同时把非 IO 的操作剥离开。

但是，单个 Reactor 承担了所有的事件监听、响应工作，如果连接过多，还是可能存在性能问题。

![](https://pic1.zhimg.com/v2-a6e0facae3d50787e2750b7c44eeede7_r.jpg?source=1940ef5c)

**多 Reactor 多线程**

为了解决单 Reactor 的性能问题，就产生了多 Reactor 的模式。其中 mainReactor 建立连接，多个 subReactor 则负责数据读写。

![](https://pic3.zhimg.com/v2-94a8da097a1fa565f3bc78b14caff94b_r.jpg?source=1940ef5c)

分布式事务
-----

对于分布式事务，相信所有人都应该很了解，为什么会有分布式事务？无论是数据量导致的分库，还是现在微服务盛行的场景都是他出现的原因。

这一篇内容还是避免不了俗套，主要的范围无非是 XA、2PC、3PC、TCC，再最后到 Seata。

但是，我认为这东西，只是适用于面试和理论的了解，你真要说这些方案实际生产中有人用吗？

有，但是会实现的更简单，不会套用理论来实现，大厂有大厂的解决方案，中小公司用框架或者压根就不存在分布式事务的问题。

那，为什么还要写这个？

为了你面试八股文啊，小可爱。

### **事务**

要说分布式事务，首先还是从事务的基本特征说起。

**A 原子性**：在事务的执行过程中，要么全部执行成功，要么都不成功。

**C 一致性**：事务在执行前后，不能破坏数据的完整性。一致性更多的说的是通过 AID 来达到目的，数据应该符合预先的定义和约束，由应用层面来保证，还有的说法是 C 是强行为了 ACID 凑出来的。

**I 隔离性**：多个事务之间是互相隔离的，事务之间不能互相干扰，涉及到不同事务的隔离级别的问题。

**D 持久性**：一旦事务提交，数据库中数据的状态就应该是永久性的。

### **XA**

XA（eXtended Architecture）是指由 X/Open 组织提出的分布式事务处理的规范，他是一个规范或者说是协议，定义了事务管理器 TM(Transaction Manager)，资源管理器 RM(Resource Manager)，和应用程序。

事务管理器 TM 就是事务的协调者，资源管理器 RM 可以认为就是一个数据库。

![](https://pic3.zhimg.com/v2-16753a74aeb939d3765ef20ce81c92c3_r.jpg?source=1940ef5c)

### **2PC**

XA 定义了规范，那么 2PC 和 3PC 就是他的具体实现方式。

2PC 叫做二阶段提交，分为投票阶段和执行阶段两个阶段。

**投票阶段**

TM 向所有的参与者发送 prepare 请求，询问是否可以执行事务，等待各个参与者的响应。

这个阶段可以认为只是执行了事务的 SQL 语句，但是还没有提交。

如果都执行成功了就返回 YES，否则返回 NO。

![](https://pica.zhimg.com/v2-b05cd3b28838ba1db628006f37a2d77f_r.jpg?source=1940ef5c)

**执行阶段**

执行阶段就是真正的事务提交的阶段，但是要考虑到失败的情况。

如果所有的参与者都返回 YES，那么就执行发送 commit 命令，参与者收到之后执行提交事务。

反之，只要有任意一个参与者返回的是 NO 的话，就发送 rollback 命令，然后执行回滚的操作。

![](https://pica.zhimg.com/v2-7808017710504585fa2391ead2845dca_r.jpg?source=1940ef5c)

**2PC 的缺陷**

1.  同步阻塞，可以看到，在执行事务的过程当中，所有数据库的资源都被锁定，如果这时候有其他人来访问这些资源，将会被阻塞，这是一个很大的性能问题。
2.  TM 单点问题，只要一个 TM，一旦 TM 宕机，那么整个流程无法继续完成。
3.  数据不一致，如果在执行阶段，参与者脑裂或者其他故障导致没有收到 commit 请求，部分提交事务，部分未提交，那么数据不一致的问题就产生了。

### **3PC**

既然 2PC 有这么多问题，所以就衍生出了 3PC 的概念，也叫做三阶段提交，他把整个流程分成了 CanCommit、PreCommit、DoCommit 三个步骤，相比 2PC，增加的就是 CanCommit 阶段。

**CanCommit**

这个阶段就是先询问数据库是否执行事务，发送一个 canCommit 的请求去询问，如果可以的话就返回 YES，反之返回 NO。

![](https://pic1.zhimg.com/v2-fc41ab778f11357fbb8fd7d13f3d489c_r.jpg?source=1940ef5c)

**PreCommit**

这个阶段就等同于 2PC 的投票阶段了，发送 preCommit 命令，然后去执行 SQL 事务，成功就返回 YES，反之返回 NO。

![](https://pica.zhimg.com/v2-4ec2dab32cc971f6097ab1e9fcc21ef9_r.jpg?source=1940ef5c)

但是，这个地方的区别在于参与者有了**超时机制**，如果参与者超时未收到 doCommit 命令的话，将会默认去提交事务。

**DoCommit**

DoCommit 阶段对应到 2PC 的执行阶段，如果上一个阶段都是收到 YES 的话，那么就发送 doCommit 命令去提交事务，反之则会发送 abort 命令去中断事务的执行。

![](https://picx.zhimg.com/v2-9b7a554b83cd0514272aa6e13d24e862_r.jpg?source=1940ef5c)

**相比 2PC 的改进**

对于 2PC 的同步阻塞的问题，我们可以看到因为 3PC 加入了参与者的超时机制，所以原来 2PC 的如果某个参与者故障导致的同步阻塞的问题时间缩短了，这是一个优化，但是并没有完全避免。

第二个单点故障的问题，同样因为超时机制的引入，一定程度上也算是优化了。

但是数据不一致的问题，这个始终没有得到解决。

举个栗子：

在 PreCommit 阶段，某个参与者发生脑裂，无法收到 TM 的请求，这时候其他参与者执行 abort 事务回滚，而脑裂的参与者超时之后继续提交事务，还是有可能发生数据不一致的问题。

那么，为什么要加入 DoCommit 这个阶段呢？就是为了引入超时机制，事先我们先确认数据库是否都可以执行事务，如果都 OK，那么才会进入后面的步骤，所以既然都可以执行，那么超时之后说明发生了问题，就自动提交事务。

### **TCC**

TCC 的模式叫做 Try、Confirm、Cancel，实际上也就是 2PC 的一个变种而已。

实现这个模式，一个事务的接口需要拆分成 3 个，也就是 Try 预占、Confirm 确认提交、最后 Cancel 回滚。

对于 TCC 来说，实际生产我基本上就没看见过有人用，考虑到原因，首先是程序员的本身素质参差不齐，多个团队协作你很难去约束别人按照你的规则来实现，另外一点就是太过于复杂。

如果说有简单的应用的话，库存的应用或许可以算做是一个。

一般库存的操作，很多实现方案里面都会会在下单的时候先预占库存，下单成功之后再实际去扣减库存，最终如果发生了异常再回退。

![](https://pic4.zhimg.com/v2-0738e86c06c9a97aefa78a03aab7fead_r.jpg?source=1940ef5c)

冻结、预占库存就是 2PC 的准备阶段，真正下单成功去扣减库存就是 2PC 的提交阶段，回滚就是某个发生异常的回滚操作，只不过在应用层面来实现了 2PC 的机制而已。

### **SAGA**

Saga 源于 1987 年普林斯顿大学的 Hecto 和 Kenneth 发表的如何处理 long lived transaction（长活事务）论文。

主要思想就是将长事务拆分成多个本地短事务。

如果全部执行成功，就正常完成了，反之，则会按照相反的顺序依次调用补偿。

SAGA 模式有两种恢复策略：

1.  向前恢复，这个模式偏向于一定要成功的场景，失败则会进行重试
2.  向后恢复，也就是发生异常的子事务依次回滚补偿

由于这个模式在国内基本没看见有谁用的，不在赘述。

### **消息队列**

基于消息队列来实现最终一致性的方案，这个相比前面的我个人认为还稍微靠谱一点，那些都是理论啊，正常生产的实现很少看见应用。

基于消息队列的可能真正在应用的还稍微多一点。

一般来说有两种方式，基于本地消息表和依赖 MQ 本身的事务消息。

本地消息表的这个方案其实更复杂，实际上我也没看到过真正谁来用。这里我以 RocketMQ 的事务消息来举例，这个方式相比本地消息表则更完全依赖 MQ 本身的特性做了解耦，释放了业务开发的复杂工作量。

![](https://picx.zhimg.com/v2-795b45987df15bba3bb1e97252874027_r.jpg?source=1940ef5c)

1.  业务发起方，调用远程接口，向 MQ 发送一条半事务消息，MQ 收到消息之后会返回给生产者一个 ACK
2.  生产者收到 ACK 之后，去执行事务，但是事务还没有提交。
3.  生产者会根据事务的执行结果来决定发送 commit 提交或者 rollback 回滚到 MQ
4.  这一点是发生异常的情况，比如生产者宕机或者其他异常导致 MQ 长时间没有收到 commit 或者 rollback 的消息，这时候 MQ 会发起状态回查。
5.  MQ 如果收到的是 commit 的话就会去投递消息，消费者正常消费消息即可。如果是 rollback 的话，则会在设置的固定时间期限内去删除消息。

这个方案基于 MQ 来保证消息事务的最终一致性，还算是一个比较合理的解决方案，只要保证 MQ 的可靠性就可以正常实施应用，业务消费方根据本身的消息重试达到最终一致性。

### **框架**

以上说的都是理论和自己实现的方式，那么分布式事务就没有框架来解决我们的问题吗？

有，其实还不少，但是没有能扛旗者出现，要说有，阿里的开源框架 Seata 还有阿里云的 GTS。

GTS（Global Transaction Service 全局事务服务）是阿里云的中间件产品，只要你用阿里云，付钱就可以用 GTS。

Seata（Simple Extensible Autonomous Transaction Architecture）则是开源的分布式事务框架，提供了对 TCC、XA、Saga 以及 AT 模式的支持。

那么，GTS 和 Seata 有什么关系呢？

实际上最开始的时候他们都是基于阿里内部的 TXC（Taobao Transaction Constructor）分布式中间件产品，然后 TXC 经过改造上了阿里云就叫做 GTS。

之后阿里的中间件团队基于 TXC 和 GTS 做出了开源的 Seata，其中 AT（Automatic Transaction）模式就是 GTS 原创的方案。

至于现在的版本，可以大致认为他们就是一样的就行了，到 2020 年，GTS 已经全面兼容了 Seata 的 GA 版本。

![](https://pica.zhimg.com/v2-a63bce8abfbd93afb5283845a850d929_r.jpg?source=1940ef5c)

整个 GTS 或者 Seata 包含以下几个核心组件：

*   Transaction Coordinator（TC）：事务协调器，维护全局事务的运行状态，负责协调并驱动全局事务的提交或回滚。
*   Transaction Manager（TM）：控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议。
*   Resource Manager（RM）：控制分支事务，负责分支注册、状态汇报，并接收事务协调器的指令，驱动分支（本地）事务的提交和回滚。

无论对于 TCC 还是原创的 AT 模式的支持，整个分布式事务的原理其实相对来说还是比较容易理解。

1.  事务开启时，TM 向 TC 注册全局事务，并且获得全局事务 XID
2.  这时候多个微服务的接口发生调用，XID 就会传播到各个微服务中，每个微服务执行事务也会向 TC 注册分支事务。
3.  之后 TM 就可以管理针对每个 XID 的事务全局提交和回滚，RM 完成分支的提交或者回滚。

![](https://pic2.zhimg.com/v2-1d49ff4baff3184867415ab5a7007c1a_r.jpg?source=1940ef5c)

**AT 模式**

原创的 AT 模式相比起 TCC 的方案来说，无需自己实现多个接口，通过代理数据源的形式生成更新前后的 UNDO_LOG，依靠 UNDO_LOG 来实现回滚的操作。

执行的流程如下：

1.  TM 向 TC 注册全局事务，获得 XID
2.  RM 则会去代理 JDBC 数据源，生成镜像的 SQL，形成 UNDO_LOG，然后向 TC 注册分支事务，把数据更新和 UNDO_LOG 在本地事务中一起提交
3.  TC 如果收到 commit 请求，则会异步去删除对应分支的 UNDO_LOG，如果是 rollback，就去查询对应分支的 UNDO_LOG，通过 UNDO_LOG 来执行回滚

![](https://pic3.zhimg.com/v2-77a993cd37b2b63e2c580a739eb14674_r.jpg?source=1940ef5c)

**TCC 模式**

相比 AT 模式代理 JDBC 数据源生成 UNDO_LOG 来生成逆向 SQL 回滚的方式，TCC 就更简单一点了。

1.  TM 向 TC 注册全局事务，获得 XID
2.  RM 向 TC 注册分支事务，然后执行 Try 方法，同时上报 Try 方法执行情况
3.  然后如果收到 TC 的 commit 请求就执行 Confirm 方法，收到 rollback 则执行 Cancel

![](https://pic2.zhimg.com/v2-124537b6127ad7bf7fa55ccbbce3b310_r.jpg?source=1940ef5c)

**XA 模式**

1.  TM 向 TC 注册全局事务，获得 XID
2.  RM 向 TC 注册分支事务，XA Start，执行 SQL，XA END，XA Prepare，然后上报分支执行情况
3.  然后如果收到 TC 的 commit 请求就执行 Confirm 方法，收到 rollback 则执行 Cancel

![](https://pic2.zhimg.com/v2-40e73de0e6ad9a82c9e2cc98deba9cbd_r.jpg?source=1940ef5c)

**SAGA 模式**

1.  TM 向 TC 注册全局事务，获得 XID
2.  RM 向 TC 注册分支事务，然后执行业务方法，并且上报分支执行情况
3.  RM 收到分支回滚，执行对应的业务回滚方法

![](https://pic1.zhimg.com/v2-f676a60f5e15339eedf6f1c84e3cffe5_r.jpg?source=1940ef5c)

### **总结**

这里从事务的 ACID 开始，向大家先说了 XA 是分布式事务处理的规范，之后谈到 2PC 和 3PC，2PC 有同步阻塞、单点故障和数据不一致的问题，3PC 在一定程度上解决了同步阻塞和单点故障的问题，但是还是没有完全解决数据不一致的问题。

之后说到 TCC、SAGA、消息队列的最终一致性的方案，TCC 由于实现过于麻烦和复杂，业务很少应用，SAGA 了解即可，国内也很少有应用到的，消息队列提供了解耦的实现方式，对于中小公司来说可能是较为低成本的实现方式。

最后再说目前国内的实现框架，云端阿里云的 GTS 兼容 Seata，非云端使用 Seata，它提供了 XA、TCC、AT、SAGA 的解决方案，可以说是目前的主流选择。

分布式锁
----

开个头，这是篇技术文章，但是昨天一天太恶心了，忍不住还是简单说下昨天的事情。

昨天早上 11 点飞大理，结果 9 点钟要出门的时候发现密码锁坏了，不用密码都能打开，一边司机师傅在催着走，一边连忙打电话给房东和客服找人维修，这是第一。

然后飞机晚点，11 点 20 飞到 4 点钟才要落地，下降的过程那叫一个颠簸，我以为都要没了，这也是第一次晕飞机，简直快吐了，这是第二。

![](https://pic1.zhimg.com/v2-25172427d5a847deaaa1bc60edbd18f6_r.jpg?source=1940ef5c)

然后快 4 点了，飞机总算快要降落了，轮子都快着地了，结果愣是拔起来又起飞了，最后知道是大理 8 级大风，机长不敢落地。。。这是第三。

最后通知起飞不知道什么时候，要等大理那边通知，没有办法，我们只好下飞机转高铁，急急忙忙的一路转，总算赶上了最后 7 点前的高铁，否则就要等到 9 点以后了，最后一路周转，9 点多总算到了酒店，好在酒店还算行，没有让我太过于失望。

这一天搞下来，整个一人在囧途，太累了。好吧，废话就这么多，文章开始。

### **说说分布式锁吧？**

对于一个单机的系统，我们可以通过 synchronized 或者 ReentrantLock 等这些常规的加锁方式来实现，然而对于一个分布式集群的系统而言，单纯的本地锁已经无法解决问题，所以就需要用到分布式锁了，通常我们都会引入三方组件或者服务来解决这个问题，比如数据库、Redis、Zookeeper 等。

通常来说，分布式锁要保证互斥性、不死锁、可重入等特点。

互斥性指的是对于同一个资源，任意时刻，都只有一个客户端能持有锁。

不死锁指的是必须要有锁超时这种机制，保证在出现问题的时候释放锁，不会出现死锁的问题。

可重入指的是对于同一个线程，可以多次重复加锁。

### **那你分别说说使用数据库、Redis 和 Zookeeper 的实现原理？**

数据库的话可以使用乐观锁或者悲观锁的实现方式。

乐观锁通常就是数据库中我们会有一个版本号，更新数据的时候通过版本号来更新，这样的话效率会比较高，悲观锁则是通过`for update`的方式，但是会带来很多问题，因为他是一个行级锁，高并发的情况下可能会导致死锁、客户端连接超时等问题，一般不推荐使用这种方式。

Redis 是通过`set`命令来实现，在`2.6.2`版本之前，实现方式可能是这样：

![](https://pic1.zhimg.com/50/v2-d8d85acf95bdb82f9470b503231d2f9d_720w.jpg?source=1940ef5c)

`setNX`命令代表当`key`不存在时返回成功，否则返回失败。

但是这种实现方式把加锁和设置过期时间的步骤分成两步，他们并不是原子操作，如果加锁成功之后程序崩溃、服务宕机等异常情况，导致没有设置过期时间，那么就会导致死锁的问题，其他线程永远都无法获取这个锁。

之后的版本中，Redis 提供了原生的`set`命令，相当于两命令合二为一，不存在原子性的问题，当然也可以通过 lua 脚本来解决。

`set`命令如下格式：

![](https://pic1.zhimg.com/v2-c84d93894693902e8b6d8cff08ce03f0_r.jpg?source=1940ef5c)key 为分布式锁的 key  
value 为分布式锁的值，一般为不同的客户端设置不同的值  
NX 代表如果要设置的 key 存在返回成功，否则返回失败  
EX 代表过期时间为秒，PX 则为毫秒，比如上面示例中为 10 秒过期

Zookeeper 是通过创建临时顺序节点的方式来实现。

![](https://pica.zhimg.com/v2-2dd3a32d8f9d07794a5b88268b5ac55e_r.jpg?source=1940ef5c)

1.  当需要对资源进行加锁时，实际上就是在父节点之下创建一个临时顺序节点。
2.  客户端 A 来对资源加锁，首先判断当前创建的节点是否为最小节点，如果是，那么加锁成功，后续加锁线程阻塞等待
3.  此时，客户端 B 也来尝试加锁，由于客户端 A 已经加锁成功，所以客户端 B 发现自己的节点并不是最小节点，就会去取到上一个节点，并且对上一节点注册监听
4.  当客户端 A 操作完成，释放锁的操作就是删除这个节点，这样就可以触发监听事件，客户端 B 就会得到通知，同样，客户端 B 判断自己是否为最小节点，如果是，那么则加锁成功

### **你说改为 set 命令之后就解决了问题？那么还会不会有其他的问题呢？**

虽然`set`解决了原子性的问题，但是还是会存在两个问题。

**锁超时问题**

比如客户端 A 加锁同时设置超时时间是 3 秒，结果 3s 之后程序逻辑还没有执行完成，锁已经释放。客户端 B 此时也来尝试加锁，那么客户端 B 也会加锁成功。

这样的话，就导致了并发的问题，如果代码幂等性没有处理好，就会导致问题产生。

![](https://pic2.zhimg.com/v2-d515772e7835622a1a82b4ed898d8c1b_r.jpg?source=1940ef5c)

**锁误删除**

还是类似的问题，客户端 A 加锁同时设置超时时间 3 秒，结果 3s 之后程序逻辑还没有执行完成，锁已经释放。客户端 B 此时也来尝试加锁，这时客户端 A 代码执行完成，执行释放锁，结果释放了客户端 B 的锁。

![](https://pica.zhimg.com/v2-ce974418702ecb7a93531a8b023fe3c8_r.jpg?source=1940ef5c)

### **那上面两个问题你有什么好的解决方案吗？**

**锁超时**

这个有两个解决方案。

1.  针对锁超时的问题，我们可以根据平时业务执行时间做大致的评估，然后根据评估的时间设置一个较为合理的超时时间，这样能一大部分程度上避免问题。
2.  自动续租，通过其他的线程为将要过期的锁延长持有时间

**锁误删除**

每个客户端的锁只能自己解锁，一般我们可以在使用`set`命令的时候生成随机的 value，解锁使用 lua 脚本判断当前锁是否自己持有的，是自己的锁才能释放。

```
#加锁
SET key random_value NX EX 10
#解锁
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
```

### **了解 RedLock 算法吗？**

因为在 Redis 的主从架构下，主从同步是异步的，如果在 Master 节点加锁成功后，指令还没有同步到 Slave 节点，此时 Master 挂掉，Slave 被提升为 Master，新的 Master 上并没有锁的数据，其他的客户端仍然可以加锁成功。

对于这种问题，Redis 作者提出了 RedLock 红锁的概念。

RedLock 的理念下需要至少 2 个 Master 节点，多个 Master 节点之间完全互相独立，彼此之间不存在主从同步和数据复制。

主要步骤如下：

1.  获取当前 Unix 时间
2.  按照顺序依次尝试从多个节点锁，如果获取锁的时间小于超时时间，并且超过半数的节点获取成功，那么加锁成功。这样做的目的就是为了避免某些节点已经宕机的情况下，客户端还在一直等待响应结果。举个例子，假设现在有 5 个节点，过期时间 = 100ms，第一个节点获取锁花费 10ms，第二个节点花费 20ms，第三个节点花费 30ms，那么最后锁的过期时间就是 100-(10+20+30)，这样就是加锁成功，反之如果最后时间 < 0，那么加锁失败
3.  如果加锁失败，那么要释放所有节点上的锁

### **那么 RedLock 有什么问题吗？**

其实 RedLock 存在不少问题，所以现在其实一般不推荐使用这种方式，而是推荐使用 Redission 的方案，他的问题主要如下几点。

**性能、资源**

因为需要对多个节点分别加锁和解锁，而一般分布式锁的应用场景都是在高并发的情况下，所以耗时较长，对性能有一定的影响。此外因为需要多个节点，使用的资源也比较多，简单来说就是费钱。

**节点崩溃重启**

比如有 1~5 号五个节点，并且没有开启持久化，客户端 A 在 1，2，3 号节点加锁成功，此时 3 号节点崩溃宕机后发生重启，就丢失了加锁信息，客户端 B 在 3，4，5 号节点加锁成功。

那么，两个客户端 A\B 同时获取到了同一个锁，问题产生了，怎么解决？

1.  Redis 作者建议的方式就是延时重启，比如 3 号节点宕机之后不要立刻重启，而是等待一段时间后再重启，这个时间必须大于锁的有效时间，也就是锁失效后再重启，这种人为干预的措施真正实施起来就比较困难了
2.  第二个方案那么就是开启持久化，但是这样对性能又造成了影响。比如如果开启 AOF 默认每秒一次刷盘，那么最多丢失一秒的数据，如果想完全不丢失的话就对性能造成较大的影响。

**GC、网络延迟**

对于 RedLock，Martin Kleppmann 提出了很多质疑，我就只举这样一个 GC 或者网络导致的例子。（这个问题比较多，我就不一一举例了，心里有一个概念就行了，文章地址：`https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html`）

从图中我们可以看出，client1 线获取到锁，然后发生 GC 停顿，超过了锁的有效时间导致锁被释放，然后锁被 client2 拿到，然后两个客户端同时拿到锁在写数据，问题产生。

![](https://pic2.zhimg.com/v2-3e57f7be3cb029a3c95ca03b8e1fc89a_r.jpg?source=1940ef5c)

**时钟跳跃**

同样的例子，假设发生网络分区，4、5 号节点变为一个独立的子网，3 号节点发生始终跳跃（不管人为操作还是同步导致）导致锁过期，这时候另外的客户端就可以从 3、4、5 号节点加锁成功，问题又发生了。

### **那你说说有什么好的解决方案吗？**

上面也提到了，其实比较好的方式是使用`Redission`，它是一个开源的 Java 版本的 Redis 客户端，无论单机、哨兵、集群环境都能支持，另外还很好地解决了锁超时、公平非公平锁、可重入等问题，也实现了`RedLock`，同时也是官方推荐的客户端版本。

### **那么 Redission 实现原理呢？**

**加锁、可重入**

首先，加锁和解锁都是通过 lua 脚本去实现的，这样做的好处是为了兼容老版本的 redis 同时保证原子性。

`KEYS[1]`为锁的 key，`ARGV[2]`为锁的 value，格式为 uuid + 线程 ID，`ARGV[1]`为过期时间。

主要的加锁逻辑也比较容易看懂，如果`key`不存在，通过 hash 的方式保存，同时设置过期时间，反之如果存在就是 + 1。

对应的就是`hincrby', KEYS[1], ARGV[2], 1`这段命令，对 hash 结构的锁重入次数 + 1。

![](https://pica.zhimg.com/v2-8d2b4325a52468f4ca8c1afb03657827_r.jpg?source=1940ef5c)

**解锁**

1.  如果 key 都不存在了，那么就直接返回
2.  如果 key、field 不匹配，那么说明不是自己的锁，不能释放，返回空
3.  释放锁，重入次数 - 1，如果还大于 0 那么久刷新过期时间，反之那么久删除锁

![](https://pic2.zhimg.com/v2-5ac5866c3a6b07979f289d74c2e92fb2_r.jpg?source=1940ef5c)

**watchdog**

也叫做看门狗，也就是解决了锁超时导致的问题，实际上就是一个后台线程，默认每隔 10 秒自动延长锁的过期时间。

默认的时间就是`internalLockLeaseTime / 3`，`internalLockLeaseTime`默认为 30 秒。

![](https://pica.zhimg.com/v2-7acb680bbfb0b67dd8bd7056a4f99c1f_r.jpg?source=1940ef5c)

### **最后，实际生产中对于不同的场景该如何选择？**

首先，如果对于并发不高并且比较简单的场景，通过数据库乐观锁或者唯一主键的形式就能解决大部分的问题。

然后，对于 Redis 实现的分布式锁来说性能高，自己去实现的话比较麻烦，要解决锁续租、lua 脚本、可重入等一系列复杂的问题。

对于单机模式而言，存在单点问题。

对于主从架构或者哨兵模式，故障转移会发生锁丢失的问题，因此产生了红锁，但是红锁的问题也比较多，并不推荐使用，推荐的使用方式是用 Redission。

但是，不管选择哪种方式，本身对于 Redis 来说不是强一致性的，某些极端场景下还是可能会存在问题。

对于 Zookeeper 的实现方式而言，本身就是保证数据一致性的，可靠性更高，所以不存在 Redis 的各种故障转移带来的问题，自己实现也比较简单，但是性能相比 Redis 稍差。

不过，实际中我们当然是有啥用啥，老板说用什么就用什么，我才不管那么多。

* * *

面试题
---

2020 年已经接近尾声了，跳槽的季节又来了，刚好，最近有好几个读者拿到了腾讯、阿里大厂的 offer，在我厚颜无耻的追问之下，他们终于给我透露出了面试题的细节，这份热乎乎、滚滚烫的面经分享给大家，希望对大家有所帮助。

**bigo 面试**
-----------

第一位读者经过 1 个多月的刷题、看书，成功拿下 bigo 和腾讯的 offer，这位读者之前也是 985 高材生，但是一直在小公司，之前和我聊了聊，透露出想去大厂的想法，这不，还是挺简单的嘛，一把就过了，成功斩获 bigo、腾讯 offer。

### **bigo 一面**

第一面的话，我觉得比较基础，都是针对 Java、SQL 基础的一些问题，然后扩展了一下对 JVM 对应到生产上的使用、调优经验，看是不是真的做过、解决过问题，要有思路。

内存泄露怎么分析？怎么知道整条内存泄露的链路？

一般方法，jmap dump 出转储文件，然后通过 MAT 等一些工具来做具体的分析。

用的什么垃圾收集器？GC 一次多久？线上多久一次 Full GC？

垃圾收集器比较简单，背背书就可以了，然后 GC 的频率这个就是根据现在公司的场景举例子说明。

怎么进行 JVM 调优？

说了一点 JVM 调优的参数，使用之类，然后结合线上的一次问题回答了怎么发现问题，最终调整 JVM 参数解决问题的过程。

项目里有用过 ConcurrentHashMap 吗？ConcurrentHashMap 底层结构有了解吗？

这个八股文看书就行了，分段锁到 CAS+synchronized 改变，get、put、resize 过程。

你知道 JDK7 和 8 之间的区别吗

说了下 Stream API 使用、lambda 表达式，HashMap 头插尾插的改变，ConcurrentHashMap 实现方式的变化。

用过 Stream 吗，讲讲

就根据平时使用说就好了，比较简单。

sql 优化的经历

也比较简单，平时用到的一些慢 SQL 优化的经历说下就行了，但是平时要有总结，不然的话就会东一棒槌西一棒槌。

算法，链表相加

通用答案，用刷题大法。

### **bigo 二面**

二面会偏中间件一点，考察了项目的细节，会被问的很细，然后其他的问题都是看看书就知道了，虽然都不难，但是还是要多看书、多总结才行。

深挖项目

项目一定要准备好，每个细节的点，有问题的地方要自己多思考，不然被问到了回答不了就很尴尬。

讲讲 ES，ES 文档数据太多了怎么办？

基本上把 ES 的所有点都讲了一遍，就差不多 OK 了，因为我做的搜索业务，所以这块的问题比较多。

RocketMQ 集群的原理，消息堆积怎么办，推拉模式优劣？

也是看书就行的，堆积的解决方案可以看我的 MQ 文章系列。

说下 Raft 协议？

也就说说主要工作原理，Leader 选举、日志复制这些。

分布式 ID 的设计方案？

很多，雪花算法，国内美团、滴滴、百度开源的记得一两个就可以了，然后找一个说说实现的原理。

比较简单的一个算法题，印象不是很清晰了，但是依稀记得是考并发工具包的设计

### **bigo 三面**

三面一上来其实还是问项目，扣细节，这一面是技术的终面了，可能是老板面，所以没有很多的技术上的难题，针对的还是个人思维方式，平时解决问题的想法和思路。

Redis 集群的特性，分布式锁的设计？

这个一般也没什么好说的，该背书就背书，分布式锁也是老生常谈的问题了。

问了项目架构，项目难点

再次被扣细节，平时要理解深刻。

算法是二分法的一个变形题，也不算难

### **bigo 面试总结**

面试难度总体来说一般，都是在网上能看得到的问题，但是必须都要会，比较顺利的拿下 offer。

**腾讯面试**
--------

因为读者已经先拿了 bigo 的 offer，接下来腾讯的面试也算是更有信心了，至少有一个 offer 打底。不过腾讯一面问的非常广泛，提问速度也很快，如果讲的明白的话，立刻就开始下一个问题... ...

### **腾讯一面**

HTTP/HTTPS，网络安全问题？

说了说他们的区别，Https 通信的机制，证书、密钥保证安全一些东西。

volatile 和 synchronize 的区别？

八股文，背！

JAVA 内存模型？

JMM 一套规则，工作内存、主内存，原子性、可见性、有序性，happens-before 等等都说了。

Redis 分布式锁？

这个挺简单的，大家都会的，另外还要说下和 zookeeper 实现方式的一些区别，实际应用的过程。

Innodb 讲讲？

把知道的都说出来就好了，行锁啊，MVCC，外键，一致性读一些东西。

ZAB 讲讲？

就说整个 ZAB 协议的过程，选举、发现、同步、广播的流程。

怎么分库分表？

这个其实还是需要点经验的，没有对应到数量级的项目的话可能还是靠背书了，参考我的分库分表文章。

怎么自己实现 IOC？

如果自己看过实现，这个就比较简单。

用过哪些设计模式，讲讲？

举例一些常见的模式，平时怎么使用的说说就行了。

怎么判断一个链表是不是有环？

刷题就好了。

一面的内容非常多，后面 Kafka，Redis，Zookeeper，ES，计算机网络都有被问到，有一些回答的不是很好，不过还是过了。

### **腾讯二面**

这一面比上一面还是好一点吧，没有那么多问题，感觉上比一面还稍微容易一点，还有一些简单的问题有点回忆不上了，项目的问题，我已经很熟了。

自我介绍？

自我介绍要准备好，不要太长也不要太短，几句话说明自己的职业生涯的情况，重点的项目，用到的技能点概括进去就行。

深挖项目，问了下商品表的设计，项目有什么亮点，或者认为有什么缺陷，怎么改进，并发有多少等等？

还是项目，深挖，没什么好说的了。

ES 讲了个遍，包括基础原理和优化？

又重新说了一遍。

分布式 ID 的生成方式？

还是老问题。

再次聊了下项目，还有分布式事务相关知识，保证数据一致性？

也是老生常谈题，面试必问。两阶段、三阶段提交，TCC 方案，还有强一致性、最终一致性等等。

为什么要用框架做分布式，没有行不行？

这种开放性的问题，说自己的思路就行了。举例子说明比如 Dubbo 这种框架解决了什么问题，如服务治理、服务编排、降级等。

### **腾讯总结**

腾讯的面试相比 bigo 更加全面，更多的考察的是中间件的原理和使用，还有就是分布式系统下的一些常规的解决方案，平时这些知识点都碰到过，但是要多总结。感觉下来，整体难度也是一般。

**附赠快手**
--------

读者非常优秀，临到采访结束之际，还要附送我一轮快手面试，只能勉为其难收入囊中。

数据库连接不上了，怎么排查？

还是看思路的问题，思考比如网络是否正常，数据库服务是否正常、权限等因素。

双亲委派模型，有什么好处？

说下原理，好处说了下安全、避免重复加载之类。

ThreadLocal 讲讲？

看过知道就能说上来。

一次接口调用，在日志文件里打印”kuaishou ”+ 耗时，比如 “kuaishou 20ms”,"kuaishou 50ms", "kuaishou 100ms"，有十万条，用 linux 的命令怎么查出来耗时最短的十条？

这个不知道，然后面试官还一直硬要我手写出来... ...

安装了一个软件，怎么在 linux 找到他的路径？

我说了 whereis。

怎么查看 jvm 里线程状态？

jstack 进程 ID 就可以了。

CountDownLatch 和 CyclicBarrier 有什么区别？

这个看过就知道了，具体可以看我的文章有写道。

jps -m ，jps -l 用过吗？

-m 可以输出主函数的传参，-l 可以输出完整包名。

讲一下 Spring 事务底层是怎么实现的？

这个问题也要看过源码，AOP 动态代理实现。

算法题：树的镜像，不能用递归写。

还是那句话，刷题完事儿。

### **快手总结**

快手的问题，嗯... 比较奇怪，然后没有什么太大问题... 一轮游了。

来自年初和最近朋友的大厂面试题。

### **阿里巴巴**

1.  对象如何进行深拷贝，除了 clone
2.  happen-before 原则
3.  jvm 调优的实践
4.  单例对象会被 jvm 的 gc 时回收吗
5.  redis 如果 list 较大，怎么优化
6.  tcp 的沾包与半包
7.  socket 编程相关的一些 api 和用法
8.  建立和处理连接的是同一个 socket 吗，socket 中两个队列分别是啥
9.  项目中有使用过 netty 吗
10.  TSL1.3 新特性
11.  AES 算法原理
12.  redis 集群的使用
13.  mysql 与 mogo 对比
14.  场景题：设计一个 im 系统包括群聊单聊
15.  场景题：设计数据库连接池
16.  场景题：秒杀场景的设计

### **美团**

1.  项目详细信息，涉及一些 aiot 交互处理，怎么实现大量的不同设备的指令编解码和指令转化，服务器的架构，自己责任模块
2.  OOM 的故障处理
3.  有没有用过分布式锁，怎么实现的，讲讲原理
4.  redis 的跳表用在哪，为什么用跳表
5.  mysql 优化的实践经验
6.  hashMap 的 1.8 与 1.7 区别
7.  netty 的原理和使用
8.  tcp 的连接过程
9.  socket 有几个队列
10.  一台服务器能支持多少连接，为什么
11.  tcp 各个参数怎么设置
12.  redis 底层基本数据类型，redis 集群原理，cluster 集群的使用
13.  mysql 存储引擎类型，索引类型，innodb 数据存储方式
14.  线程池的参数说明，rejectHandler 说明
15.  volatile 的原理
16.  jvm 有哪几种垃圾回收器，各自的应用场景
17.  g1 回收器的特征
18.  jvm 结构
19.  负载均衡器的四层和七层负载均衡原理
20.  场景题：设计一个高可用高并发的电商系统

### **腾讯**

1.  kafka 生产端怎么实现幂等的
2.  kafka 如何实现分布式消息
3.  kafka 的 slave 的同步机制
4.  kafka 怎么进行消息写入的 ack
5.  为什么实现 equals 必须先实现 hash 方法
6.  一个对象 new 出来后的结构，怎么保存的
7.  讲一讲类加载的过程
8.  redis 的 hash 数据结构和如何扩容
9.  mysql 快照读怎么实现的
10.  msyql 的事务隔离级别，不可重复读和幻读区别  
    

### **YY**

1.  JVM 调优思路
2.  redis cluster 集群扩容怎么数据平滑过度，从客户端设计
3.  mysql 的 sql 本身没问题的情况下，没走索引原因（反复强调 sql 没问题，不需要从 sql 角度考虑）
4.  kafka 如何确保消息不丢失
5.  分库分表如何进行跨库联合查询
6.  限流设计用 java 实现，不能用工具类库
7.  dubbo 的设计和完整调用过程（要详细）
8.  es 的脑裂问题怎么解决

### **毒（得物）**

1.  new 一个对象的过程发生了什么
2.  spring 循环引用解决的原理是什么？
3.  FactoryBean 和 BeanFactory 区别
4.  Synchronized 原理？
5.  CAS volatile 原理？
6.  内存模型？什么是主内存？什么是工作内存？
7.  数据库索引类型？原理？
8.  Spring Bean 生命周期？
9.  mysql 优化经验？
10.  mysql 锁类型？
11.  redis 使用过程中应该注意什么问题？
12.  JVM 调优参数？
13.  线程池原理？属性代表含义？
14.  HashMap ConcurrentHashMap 原理？

### **饿了么**

1.  项目介绍，怎么不断优化项目、架构升级？如果业务量剧增，怎么保证系统高可用、扩展性？
2.  订单量、日新增多少？分库分表怎么做？基于什么维度去做？
3.  检测到 jvm 内存大于配置 jvm 的 xmx 配置的内存， 三台机器中的一台机器有上面这种现象，如何解释？
4.  redis 热 key 怎么解决？
5.  kafka 为什么性能高？
6.  OOM 场景分析？
7.  mysql 集群是怎么部署的，主从同步？
8.  怎么设置使用什么 GC 方式？不同年代 GC 收集器有哪些？
9.  线上 CPU 很高怎么排查
10.  jdk1.8 的新特性
11.  BIO\NIO 了解
12.  mq 怎么保证消息可靠性？
13.  系统负载过高怎么办、什么问题导致的？怎么排查？
14.  linux 操作系统简单介绍有哪些东西？

### **中通**

1.  JVM 介绍
2.  JMM 模型
3.  gc root 有哪些？
4.  JVM 调优经验？
5.  线程池注意事项，异常处理
6.  分布式锁使用和原理？
7.  redis 怎么持久化？高可用？
8.  rpc 框架实现原理？
9.  接口调用变慢排查
10.  业务系统架构，业务量
11.  数据库设计，优化方案

### **鱼泡泡（比心）**

1.  比较有成就的项目
2.  清结算怎么实现的？
3.  统一收银台设计？
4.  rocketMq 和 kafka 区别，选型？
5.  kafka 消息从生产到消费的流转过程？
6.  hashMap hashTable 区别？
7.  对线程安全的理解？
8.  CAS 实现原理？
9.  代码加锁有几种实现方式？
10.  快速排序算法
11.  分布式锁获取锁失败的处理，线程间的同步？
12.  redis 线程模型，过期机制，淘汰策略？
13.  线程池参数，使用场景，参数设置分析？
14.  mysql 存储引擎，索引结构，分库分表
15.  场景题：设计一个抢红包系统